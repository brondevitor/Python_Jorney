{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na aula passa abordamos um processo de busca automática pelos melhores hiperparâmetros.Na prática, para usar esse método precisamos:\n",
    "\n",
    "1. Dividir os dados em treino e teste. Lembrando que, para conjuntos maiores (>1MM) dividimos em treino, teste e validação. \n",
    "2. Definir uma malha de hiperparâmetros (ver sempre na biblioteca os hiperparâmetros dos algoritmos que se deseja utilizar)\n",
    "3. Definir o tipo de validaçao cruzada (se for classificação, usar StratifiedKFold)\n",
    "4. Definir um método de busca (até agora vimos que Grid Search e hoje veremos Randomized Search)\n",
    "\n",
    "Para cada combinação de hiperparâmetros definidos pelas malhas, o algoritmo realiza uma validação cruzada, o que lhe permitirá estimar o erro em produção para aquele conjunto específico. No final, ele nos retorna o conjunto de hiperparâmetros para o qual o erro estimado é mínimo.\n",
    "\n",
    "No final, devemos sempre treinar nossos dados no X_train e avaliar a performance no X_test, ainda não visto. Essa será a performance estimada em produção.\n",
    "\n",
    "OBS 1 : Caso o conjunto de dados seja relativamente grande, não será realizada validação cruzada. Apenas um processo iterativo e automático de busca será realizado. Nesse caso, o algoritmo retorna pra gente a combinação que produz o menor erro no conjunto de validação. No final, treinamos o modelo no X_train e estimamos a performance no final utilizando o X_test.\n",
    "\n",
    "OBS 2: Em um conjunto menor de dados, seria interessante utilizar um método de validação conhecido como Nested Cross Validation. Para mais informações, acessem o [link](https://weina.me/nested-cross-validation/)\n",
    "\n",
    "OBS 3: No caso de dados grandes, não precisamos da validaçao cruzada, então não faz sentido utilizar GridSearchCV ou RandomizedSearchCV. Podemos, em vez disso, utilizar as classes ParameterGrid e ParameterSampler do sklearn para realizar nosso processo de busca."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos a grid de parâmetros da mesma forma que aprendemos, mas não usaremos GridSearchCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em vez disso, utilizaremos a clase ParameterGrid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid de hiperparâmetros\n",
    "param_grid = {'n_neighbors': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': [1, 2]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir daí, criamos o grid com todas as combinações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.model_selection._search.ParameterGrid at 0x117ccffd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ParameterGrid(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 1}\n",
      "{'n_neighbors': 2}\n"
     ]
    }
   ],
   "source": [
    "validation_error = []\n",
    "for combinacao in ParameterGrid(param_grid):\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_val = knn.predict(X_val)\n",
    "    erro = accuracy_score(y_val_real, y_val)\n",
    "    validation_error.append(erro)\n",
    "    print(combinacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prática, não faremos validação cruzada. Apenas iremos treinar e validar (**validar significa avaliar o erro no dataset de validação!**) um modelo para cada combinação do dicionário acima e checar qual retorna para nós o menor erro de validação. Com isso, treinamos nosso modelo no```X_train```imamos a performance dele no ```X_Test```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDq8-uvlIQeE"
   },
   "source": [
    "# Randomized Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Grid Search pode ser considerado um método por exaustão para escolher o melhor conjunto de hiperparâmetros. No Grid Search, o cientista de dados configura uma grade de valores de hiperparâmetros e, para cada combinação, treina um modelo e pontua nos dados de teste. Nessa abordagem, todas as combinações de valores de hiperparâmetros são testadas, o que pode ser muito ineficiente. Por exemplo, pesquisar 20 valores de parâmetros diferentes para cada um dos 4 parâmetros exigirá 160.000 tentativas de validação cruzada. Isso equivale a 1.600.000 ajustes de modelo e 1.600.000 previsões se a validação cruzada de 10 vezes for usada. Embora o Scikit Learn ofereça a função GridSearchCV para simplificar o processo, seria uma execução extremamente cara em termos de capacidade e tempo de computação.\n",
    "Em contraste,o Randomized Search configura uma grade de valores de hiperparâmetros e seleciona combinações aleatórias para treinar o modelo e avaliar o erro. Isso permite que você controle explicitamente o número de combinações de parâmetros que são tentadas. O número de iterações de pesquisa é definido com base no tempo ou recursos. O Scikit Learn oferece a função RandomizedSearchCV para esse processo.\n",
    "Embora seja possível que RandomizedSearchCV não encontre um resultado tão preciso quanto GridSearchCV, ele surpreendentemente escolhe o melhor resultado com mais frequência do que não e em uma fração do tempo que GridSearchCV levaria. Com os mesmos recursos, o Random Search pode até superar o Grid Search. Isso pode ser visualizado no gráfico abaixo quando parâmetros contínuos são usados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1400/1*9W1MrRkHi0YFmBoHi9Y2Ow.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O RandomizedSearch é baseado em distribuições, ou seja, ele pode selecionar valores entre um intervalo de valores, diferentemente do GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParameterSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando queremos usar uma grid aleatória (Random Search), mas sem validação cruzada, podemos usar a classe ```ParameterSampler``` do sklearn. Essa classe vai receber o dicionário com as distribuições dos parâmetros e o número de iterações. \n",
    "A cada iteração em um loop, ele vai gerar um valor aleatório de combinação de hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats import loguniform, uniform, randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict()\n",
    "param_grid['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "param_grid['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "param_grid['C'] = loguniform(1e-5, 100)\n",
    "param_grid['whatever'] = randint(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.model_selection._search.ParameterSampler at 0x1182b4970>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ParameterSampler(param_grid, n_iter=10, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.750385268090156, 'penalty': 'l2', 'solver': 'liblinear', 'whatever': 989}\n",
      "{'C': 0.6857944800896927, 'penalty': 'l1', 'solver': 'liblinear', 'whatever': 124}\n",
      "{'C': 2.8853223070403433, 'penalty': 'l1', 'solver': 'newton-cg', 'whatever': 114}\n",
      "{'C': 0.023255373037796706, 'penalty': 'l1', 'solver': 'newton-cg', 'whatever': 943}\n",
      "{'C': 0.24616089675634506, 'penalty': 'l1', 'solver': 'liblinear', 'whatever': 254}\n",
      "{'C': 0.7299384488053402, 'penalty': 'none', 'solver': 'newton-cg', 'whatever': 818}\n",
      "{'C': 0.00018942710113933008, 'penalty': 'l2', 'solver': 'newton-cg', 'whatever': 40}\n",
      "{'C': 0.9689720939864422, 'penalty': 'elasticnet', 'solver': 'newton-cg', 'whatever': 958}\n",
      "{'C': 8.831257714012057, 'penalty': 'l1', 'solver': 'newton-cg', 'whatever': 861}\n",
      "{'C': 1.140522028920257, 'penalty': 'l1', 'solver': 'lbfgs', 'whatever': 631}\n"
     ]
    }
   ],
   "source": [
    "for combinacao in ParameterSampler(param_grid, n_iter=10, random_state=123):\n",
    "    \n",
    "    print(combinacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busca Bayesiana (Bônus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, iremos falar da busca bayesiana. Esse nome \"bayesiano\" já foi falado mais de uma vez durante o curso. Realmente, bayes trouxe diversas contribuições para a estatística. A busca bayesiana vai se basear em probabilidades e em atualização dessa probabilidade, tal como no teorema de bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O grande ponto de falha dos métodos que vimos é que eles não levam em consideração erros do passado. Se uma determinada região do espaço trouxe performances abaixo do esperado, é razoável parar de procurar naquela região. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sigopt.com/wp-content/uploads/2016/12/figure3.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As abordagens bayesianas, em contraste com o Random Search ou Grid Search, rastreiam os resultados de avaliações anteriores que usam para formar um modelo probabilístico de mapeamento de hiperparâmetros. Dessa forma, ao criar esse modelo probabilístico, o algoritmo consegue estimar o ponto no espaço em que a probabilidade de obter um erro menor é maior. \n",
    "\n",
    "Na literatura, esse modelo é chamado de “surrogate” da função objetivo e é representado como p (y | x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prática Guiada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 30, 120, 30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separando x e y\n",
    "df = load_iris()\n",
    "X = df.data\n",
    "y = df.target\n",
    "# Split de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=123)\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified kfold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(n_neighbors=range(1,31))\n",
    "knn = KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': range(1, 31)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search\n",
    "random_search = RandomizedSearchCV(knn, param_grid, n_iter=10, cv=skf, scoring='neg_log_loss', verbose=1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=123, shuffle=True),\n",
       "                   estimator=KNeighborsClassifier(),\n",
       "                   param_distributions={'n_neighbors': range(1, 31)},\n",
       "                   random_state=123, scoring='neg_log_loss', verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 12}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07803933303339768"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=skf, scoring='neg_log_loss', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=123, shuffle=True),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': range(1, 31)}, scoring='neg_log_loss',\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 12}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07803933303339768"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o grid search demorou mais que o dobro de tempo para rodar. No final, o random search conseguiu encontrar o melhor número de vizinhos mais próximos, com menos modelos."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "GridSearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
