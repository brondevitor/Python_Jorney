{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "\n",
    "Vamos usar os conhecimentos sobre Validação para encontrar o melhor valor de vizinhos mais próximos para um classificador ```KNeighborsClassifier```. Lembre que mostramos algumas formas de validar modelos de machine learning, que nada mais é um processo de estimar o erro/performance que um modelo terá em produção. A partir dos resultados, podemos checar se o modelo sofre de overfitting ou underfitting. Vamos utilizar essa mesma técnica para identificar de que formas podemos melhorar nosso modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split,learning_curve,KFold, StratifiedKFold, LeaveOneOut, cross_validate, validation_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados\n",
    "df_churn = pd.read_csv('churn.csv')\n",
    "df_churn.drop(['State' , 'International plan' , 'Voice mail plan'] , axis=1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn['Churn'] = df_churn['Churn'].map({False:0, True:1})\n",
    "X , y = df_churn.drop('Churn' , axis=1), df_churn['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de tudo, vamos preparar nossos Folds de validação cruzada. Vamos preparar a validação KFold, KFold-Estratificada e Leave One Out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K Fold\n",
    "cv_kfold = KFold(n_splits=10, shuffle= True, random_state=123)\n",
    "#K Fold Estratificado\n",
    "cv_kfold_stratified = StratifiedKFold(n_splits=10 , shuffle = True , random_state=123)\n",
    "# Leave one out\n",
    "cv_leave_one_out = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "\n",
    "knn_baseline = Pipeline(steps=[('pre_processor' , MinMaxScaler()),\n",
    "                              ('model', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_kfold_results = cross_validate(estimator=knn_baseline,\n",
    "                                 X=X_train,\n",
    "                                 y=y_train,\n",
    "                                 scoring='neg_log_loss',\n",
    "                                 cv=cv_kfold,\n",
    "                                 return_train_score=True,\n",
    "                                 n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss Modelo Default - KFold Treino: -0.18788942989904733\n",
      "Log Loss Modelo Default - KFold Teste: -1.6946757956069116\n"
     ]
    }
   ],
   "source": [
    "train_scores_cv_kfold_default = cv_kfold_results['train_score']\n",
    "test_scores_cv_kfold_default = cv_kfold_results['test_score']\n",
    "print(f'Log Loss Modelo Default - KFold Treino: {np.mean(train_scores_cv_kfold_default)}')\n",
    "print(f'Log Loss Modelo Default - KFold Teste: {np.mean(test_scores_cv_kfold_default)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Houve Overfiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold Estratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_kfold_stratified_results = cross_validate(estimator=knn_baseline,\n",
    "                                            X=X_train,\n",
    "                                            y=y_train,\n",
    "                                            scoring='neg_log_loss',\n",
    "                                            return_train_score=True,\n",
    "                                            n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss Modelo Default - Kfold Stratified Treino: -0.18977570092074364\n",
      "Log Loss Modelo Default - Kfold Stratified Teste: -1.6941870894194788\n"
     ]
    }
   ],
   "source": [
    "train_scores_cv_kfold_stratified_default = cv_kfold_stratified_results['train_score']\n",
    "test_scores_cv_kfold_stratified_default = cv_kfold_stratified_results['test_score']\n",
    "print(f'Log Loss Modelo Default - Kfold Stratified Treino: {np.mean(train_scores_cv_kfold_stratified_default)}')\n",
    "print(f'Log Loss Modelo Default - Kfold Stratified Teste: {np.mean(test_scores_cv_kfold_stratified_default)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A performance da KFold estratificada foi um pouco pior no Teste. Lembre que quando utilizamos o Log loss como métrica, quanto mais perto de zero melhor. Isso pode ser um indício de desbalanceamento nos folds não estrtificados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_scorer(y_true, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None):\n",
    "    return -log_loss(y_true, y_pred, eps, normalize, sample_weight, labels=__LABELS__)\n",
    "global __LABELS__\n",
    "__LABELS__ = list(set(df_churn['Churn']))\n",
    "scorer_loss = make_scorer(loss_scorer, greater_is_better=True, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_loo_default_results = cross_validate(estimator=knn_baseline,\n",
    "                                               X=X_train,\n",
    "                                               y=y_train,\n",
    "                                               scoring=scorer_loss,\n",
    "                                               cv=cv_leave_one_out,\n",
    "                                               return_train_score=True,\n",
    "                                               n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss Modelo Default - KFold Stratified Treino: nan\n",
      "Log Loss Modelo Default - KFold Stratified Teste: nan\n"
     ]
    }
   ],
   "source": [
    "train_scores_cv_loo_default = cv_loo_default_results['train_score']\n",
    "test_scores_cv_default = cv_loo_default_results['test_score']\n",
    "print(f'Log Loss Modelo Default - KFold Stratified Treino: {np.mean(train_scores_cv_loo_default)}')\n",
    "print(f'Log Loss Modelo Default - KFold Stratified Teste: {np.mean(test_scores_cv_default)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log loss treino baseline: -0.1870362137489609\n",
      "log loss teste baseline: -1.8030285835689726\n"
     ]
    }
   ],
   "source": [
    "knn_baseline.fit(X_train, y_train)\n",
    "print(f'log loss treino baseline: {-log_loss(y_train, knn_baseline.predict_proba(X_train))}')\n",
    "print(f'log loss teste baseline: {-log_loss(y_test, knn_baseline.predict_proba(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimização dos K-Vizinhos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos criar uma lista de parâmetros com vários valores de vizinhos mais próximos e tentar obter o melhor, baseando-se na ```validation_curve```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_range = list(np.arange(1,101, 2))\n",
    "param_name = 'model__n_neighbors'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar uma função auxiliar que irá realizar os cálculos da ```validation_curve``` e ao mesmo tempo plotar o gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(estimator=None, X=None, y=None, param_name=None, param_range=None, scoring=None, cv=None):\n",
    "    \n",
    "    train_score, val_score = validation_curve(estimator=estimator, \n",
    "                                          X=X, \n",
    "                                          y=y, \n",
    "                                          param_name=param_name, \n",
    "                                          param_range=param_range,\n",
    "                                          scoring=scoring,\n",
    "                                          n_jobs=-1,\n",
    "                                          cv=cv) \n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    # plotando as curvas de teste e validação\n",
    "    plt.plot(param_range, np.mean(train_score,1), color='blue', label='training score')\n",
    "    plt.plot(param_range, np.mean(val_score, 1), color='red', label='validation score')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Param_Range')\n",
    "    plt.ylabel('Score')\n",
    "    best_param = param_range[np.argmax(np.mean(val_score,1))]\n",
    "    return best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold Estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curva de Aprendizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já falamos um pouco sobre trade-off viés-variância. Temos sempre que encontrar um balanço entre os dois, buscando um modelo que não é nem tão complexo nem tão simples pra resolver nosso problema. Se um modelo é  muito simpoles, não vai conseguir ser flexível o suficiente para capturar os padrões dos dados, ao passo que um modelo muito complexo, que é muito flexível, vai acabar se ajustando demais aos dados de treino e é muito sensível a eles, de forma que ele acaba decorando o ruído e não generalizando bem para dados de produção.\n",
    "\n",
    "\n",
    "<img src=\"https://storybydata.com/wp-content/uploads/2019/02/1_9hPX9pAO3jqLrzt0IE3JzA.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que você pode fazer, caso seu modelo não fique bom depois da modelagem? Há algumas coisas que é possível fazer, quando isso ocorre:\n",
    "- Coletar mais dados\n",
    "- Diminuir o conjunto de features. Isso mesmo, diminuir o conjunto de features vai reduzir a complexidade de um modelo, diminuindo a propensão ao overfitting.\n",
    "- Aumentar o conjunto de features. Poder ser pela coleta de mais colunas ou então pela criação, por meio do processo de feature engineering que vimos. Isso aumentará a complexidade do modelo, o que reduzirá underfitting.\n",
    "- Redução de regularização. A redução de regularização varia de modelo para modelo. No SVM, por exemplo, a regularização é o parâmetro C. Mas há outros parâmetros em outros modelos, que fazem esse papel.Isso aumentará a complexidade do modelo e reduzirá a propensão a underfitting.\n",
    "- Aumento de regularização. O aumento de regularização, por sua vez, nos traz um redução de complexidade, o que ajudará em casos de overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maravilha, agora sabemos como agir diante de um modelo ruim. Mas a questão que fica é:\n",
    "Como sabemos qual desses métodos tentar primeiro?. \n",
    "A resposta é simples: Depende. Vai depender se o seu modelo tá sofrendo de alto viés ou alta variância.\n",
    "E como podemos detectar alto viés o alta variância? Isso mesmo! Curvas de aprendizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curvas de aprendizado mostram a relação entre o tamanho do conjunto de treinamento e a métrica de avaliação do modelo no conjunto de validação. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia principal é que se o algoritmo estiver aprendendo, quanto mais dados fornecemos melhor ele fica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/models.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com mais dados de treino, mais ajustado vai ficando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/learning_curves.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipos de Curva:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alto Bias e Baixa Variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A curva abaixo sofre de alto viés e baixa variância. Note que quando aumentamos o conjunto de treino, praticamente nada muda. Ou seja, o modelo não está aprendendo bem. Além disso, o erro é alto tanto no treino quanto no teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/Learning_curves_12_1.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse gráfico nos mostra algo importante: Não adianta coletar mais dados, porque não há nenhuma expectativa de melhoria com isso. Em vez disso, poderíamos tentar mudar o modelo (pegar um modelo mais flexível que consiga entender padrões mais complexos), ou até mesmo adicionar features. Note que adicionar features é diferente de adicionar mais linhas! No nosso caso, adicionar features aumentaria a complexidade do modelo e é disso que precisamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM suma, um erro alto de validação indica problema com viés. Para saber se o viés está alto ou baixo, olhamos a curva de treino. Quando o erro do treino também é alto, temos um caso de viés alto. Quando o erro do treino é baixo, temos um caso de viés baixo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/low_high_bias.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para analisar a variância, por sua vez, podemos ver o gap entre as duas curvas. um Gap muito grande, indica que as performances estão bem diferentes, o que indica alta variância."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/low_high_var.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelo formato de nossa curva, podemos concluir que se trata de um caso de Alto viés e Baixa variância. O erro é alto no treino e na validação e as curvas são próximas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ALta Variância e Baixo Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/Learning_curves_15_0.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso, mudamos o modelo para um random forest. O random forest é um modelo mais flexível e, portanto, consegue ajustar melhor os dados. Note que o erro de treino decresceu consideravelmente e o erro de validação também decresceu. Contudo, aumentamos o gap entre as curvas. De forma geral, dizemos que o Viés baixou (decorrente de um modelo mais flexível) e a variância aumentou."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso, podemos:\n",
    "- Coletar mais dados\n",
    "- Aumentar a regularização do algoritmo usado\n",
    "- Reduzir o número de features. Feature Selection Matters!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Baixa Variâcia e Baixo Viés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando conseguimos controlar viés e variância bem, encontramos o erro irredutível. Na prática é muito difícil de alcançá-lo. Principalmente, pois não sabemos o seu valor!. Na vida real, o que vai limitar sua busca por um erro irredutível é o tempo e os recursos disponíveis!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/irr_error.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mais info sobre learning curves: \n",
    "    - https://www.ritchieng.com/machinelearning-learning-curve/\n",
    "    - https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos checar a curva de aprendizado do nosso modelo?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "PRACTICA GUIADA - Integrando conceptos nuevos_pt_br.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
