{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "\n",
    "Vamos usar os conhecimentos da aula passada (Validação I) para encontrar o melhor valor de vizinhos mais próximos para um classificador ```KNeighborsClassifier```. Lembre que mostramos algumas formas de validar modelos de machine learning, que nada mais é um processo de estimar o erro/performance que um modelo terá em produção. A partir dos resultados, podemos checar se o modelo sofre de overfitting ou underfitting. Vamos utilizar essa mesma técnica para identificar de que formas podemos melhorar nosso modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split,learning_curve,KFold, StratifiedKFold, LeaveOneOut, cross_validate, validation_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados\n",
    "df_churn = pd.read_csv('churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  K-vizinhos (Default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de tudo, vamos preparar nossos Folds de validação cruzada. Vamos preparar a validação KFold, KFold-Estratificada e Leave One Out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold Estratificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave One Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correção para log loss \n",
    "def loss_scorer(y_true, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None):\n",
    "    return -log_loss(y_true, y_pred, eps, normalize, sample_weight, labels=__LABELS__)\n",
    "global __LABELS__\n",
    "__LABELS__ = list(set(df_churn['Churn']))\n",
    "scorer_loss = make_scorer(loss_scorer, greater_is_better=True, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimização dos K-Vizinhos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vamos criar uma lista de parâmetros com vários valores de vizinhos mais próximos e tentar obter o melhor, baseando-se na ```validation_curve```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar uma função auxiliar que irá realizar os cálculos da ```validation_curve``` e ao mesmo tempo plotar o gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold Estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curva de Aprendizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já falamos um pouco sobre trade-off viés-variância. Temos sempre que encontrar um balanço entre os dois, buscando um modelo que não é nem tão complexo nem tão simples pra resolver nosso problema. Se um modelo é  muito simpoles, não vai conseguir ser flexível o suficiente para capturar os padrões dos dados, ao passo que um modelo muito complexo, que é muito flexível, vai acabar se ajustando demais aos dados de treino e é muito sensível a eles, de forma que ele acaba decorando o ruído e não generalizando bem para dados de produção.\n",
    "\n",
    "\n",
    "<img src=\"https://storybydata.com/wp-content/uploads/2019/02/1_9hPX9pAO3jqLrzt0IE3JzA.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que você pode fazer, caso seu modelo não fique bom depois da modelagem? Há algumas coisas que é possível fazer, quando isso ocorre:\n",
    "- Coletar mais dados\n",
    "- Diminuir o conjunto de features. Isso mesmo, diminuir o conjunto de features vai reduzir a complexidade de um modelo, diminuindo a propensão ao overfitting.\n",
    "- Aumentar o conjunto de features. Poder ser pela coleta de mais colunas ou então pela criação, por meio do processo de feature engineering que vimos. Isso aumentará a complexidade do modelo, o que reduzirá underfitting.\n",
    "- Redução de regularização. A redução de regularização varia de modelo para modelo. No SVM, por exemplo, a regularização é o parâmetro C. Mas há outros parâmetros em outros modelos, que fazem esse papel.Isso aumentará a complexidade do modelo e reduzirá a propensão a underfitting.\n",
    "- Aumento de regularização. O aumento de regularização, por sua vez, nos traz um redução de complexidade, o que ajudará em casos de overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maravilha, agora sabemos como agir diante de um modelo ruim. Mas a questão que fica é:\n",
    "Como sabemos qual desses métodos tentar primeiro?. \n",
    "A resposta é simples: Depende. Vai depender se o seu modelo tá sofrendo de alto viés ou alta variância.\n",
    "E como podemos detectar alto viés o alta variância? Isso mesmo! Curvas de aprendizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curvas de aprendizado mostram a relação entre o tamanho do conjunto de treinamento e a métrica de avaliação do modelo no conjunto de validação. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia principal é que se o algoritmo estiver aprendendo, quanto mais dados fornecemos melhor ele fica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/models.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com mais dados de treino, mais ajustado vai ficando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/learning_curves.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipos de Curva:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alto Bias e Baixa Variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A curva abaixo sofre de alto viés e baixa variância. Note que quando aumentamos o conjunto de treino, praticamente nada muda. Ou seja, o modelo não está aprendendo bem. Além disso, o erro é alto tanto no treino quanto no teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/Learning_curves_12_1.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse gráfico nos mostra algo importante: Não adianta coletar mais dados, porque não há nenhuma expectativa de melhoria com isso. Em vez disso, poderíamos tentar mudar o modelo (pegar um modelo mais flexível que consiga entender padrões mais complexos), ou até mesmo adicionar features. Note que adicionar features é diferente de adicionar mais linhas! No nosso caso, adicionar features aumentaria a complexidade do modelo e é disso que precisamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM suma, um erro alto de validação indica problema com viés. Para saber se o viés está alto ou baixo, olhamos a curva de treino. Quando o erro do treino também é alto, temos um caso de viés alto. Quando o erro do treino é baixo, temos um caso de viés baixo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/low_high_bias.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para analisar a variância, por sua vez, podemos ver o gap entre as duas curvas. um Gap muito grande, indica que as performances estão bem diferentes, o que indica alta variância."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/low_high_var.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelo formato de nossa curva, podemos concluir que se trata de um caso de Alto viés e Baixa variância. O erro é alto no treino e na validação e as curvas são próximas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ALta Variância e Baixo Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/Learning_curves_15_0.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso, mudamos o modelo para um random forest. O random forest é um modelo mais flexível e, portanto, consegue ajustar melhor os dados. Note que o erro de treino decresceu consideravelmente e o erro de validação também decresceu. Contudo, aumentamos o gap entre as curvas. De forma geral, dizemos que o Viés baixou (decorrente de um modelo mais flexível) e a variância aumentou."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso, podemos:\n",
    "- Coletar mais dados\n",
    "- Aumentar a regularização do algoritmo usado\n",
    "- Reduzir o número de features. Feature Selection Matters!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Baixa Variâcia e Baixo Viés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando conseguimos controlar viés e variância bem, encontramos o erro irredutível. Na prática é muito difícil de alcançá-lo. Principalmente, pois não sabemos o seu valor!. Na vida real, o que vai limitar sua busca por um erro irredutível é o tempo e os recursos disponíveis!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dataquest.io/wp-content/uploads/2019/01/irr_error.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mais info sobre learning curves: \n",
    "    - https://www.ritchieng.com/machinelearning-learning-curve/\n",
    "    - https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos checar a curva de aprendizado do nosso modelo?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "PRACTICA GUIADA - Integrando conceptos nuevos_pt_br.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
