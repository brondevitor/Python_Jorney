{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regulariza√ß√£o em Machine Learning\n",
    "\n",
    "Um dos principais aspectos do treinamento do seu modelo de aprendizado de m√°quina √© evitar o overfitting, pois neste caso o modelo ter√° uma baixa precis√£o. Isso acontece porque o seu modelo dificilmente ir√° conseguir capturar o ru√≠do em seu conjunto de dados de treinamento. Por ru√≠do, queremos dizer os pontos de dados que realmente n√£o representam as propriedades reais de seus dados, mas de chance aleat√≥ria. Aprender esses pontos de dados torna o seu modelo mais flex√≠vel, sob o risco de overfitting.\n",
    "\n",
    "O conceito de balanceamento de vi√©s e vari√¢ncia √© √∫til para entender o fen√¥meno do overfitting e varia√ß√£o de balanceamento, para controlar erros do Machine Leanrning.\n",
    "\n",
    "## Formas de Regulariza√ß√£o\n",
    "\n",
    "Vamos abordar aqui duas formas de se fazer a regulariza√ß√£o:\n",
    "\n",
    "I. Aumentar o conjunto de dados (n√∫mero de observa√ß√µes) \\\n",
    "II. Penaliza√ß√£o dos otimizadores\n",
    "\n",
    "## Aumento do conjunto de dados\n",
    "\n",
    "O Overfitting pode ser controlado aumentando o tamanho do conjunto de dados de treinamento. Aumentar o tamanho do conjunto de dados para evitar ajustes excessivos se refere ao aumento do n√∫mero de observa√ß√µes (ou linhas) e n√£o do n√∫mero de recursos (ou colunas). A adi√ß√£o de colunas pode levar ao aumento da complexidade do problema e, portanto, pode resultar em um pior desempenho. A seguir veremos um exemplo de como aumentar um conjunto de dados para Regularizar um modelo\n",
    "\n",
    "## Penaliza√ß√£o de otimizadores\n",
    "\n",
    "Regulariza√ß√£o √© uma t√©cnica que restringe/regulariza/reduz as estimativas dos coeficientes, diminuiindo seus valores, que ficam portanto mais pr√≥ximos de zero. Em outras palavras, esta t√©cnica desencoraja a aprendizagem de um modelo mais complexo ou flex√≠vel, de modo a evitar o risco de overfitting.\n",
    "\n",
    "Uma rela√ß√£o simples de regress√£o linear se parece com a f√≥rmula abaixo, onde $y$ representa a rela√ß√£o aprendida e ùúÉ representa as estimativas de coeficiente para diferentes vari√°veis ou preditores (x).\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "$$y = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\theta_3x_3 + ... + \\theta_nx_n$$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "O procedimento de ajuste envolve uma fun√ß√£o de perda, conhecida como soma residual de quadrados ou RSS, sendo que os coeficientes s√£o escolhidos, de forma que minimizem essa fun√ß√£o de perda.\n",
    "\n",
    "A regulariza√ß√£o ajustar√° os coeficientes com base nos seus dados de treinamento. Se houver ru√≠do nos dados de treinamento, os coeficientes estimados n√£o ser√£o generalizados nos dados futuros. √â aqui que a regulariza√ß√£o entra e encolhe ou regulariza essas estimativas aprendidas para zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "# Tipos de Regulariza√ß√£o por Penaliza√ß√£o dos Otimizadores\n",
    "\n",
    "1. Ridge\n",
    "2. Lasso\n",
    "3. ElasticNet\n",
    "\n",
    "## 1. Ridge Regression\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "$$Ridge : \\lambda \\sum_{i=1}^{n} \\theta_i^2$$\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "A f√≥rmula acima mostra o coeficiente de Ridge que modifica a regress√£o pela adi√ß√£o da quantidade de contra√ß√£o. Agora, os coeficientes s√£o estimados minimizando essa fun√ß√£o, e o Œª √© o par√¢metro de sintonia que decide quanto queremos penalizar a flexibilidade do nosso modelo. O aumento na flexibilidade de um modelo √© representado pelo aumento de seus coeficientes e, se quisermos minimizar a fun√ß√£o acima, esses coeficientes precisam ser pequenos. √â assim que a t√©cnica de regress√£o de Ridge impede que os coeficientes subam demais. Al√©m disso, observe que encolhemos a associa√ß√£o estimada de cada vari√°vel com a resposta, exceto o intercepto $\\theta_0$. \n",
    "\n",
    "Quando Œª = 0, o termo de penalidade n√£o tem efeito, e as estimativas produzidas por regress√£o de ridge ser√£o iguais a m√≠nimos quadrados. No entanto, como Œª ‚Üí ‚àû, o impacto da penalidade de contra√ß√£o aumenta, e as estimativas coeficientes da regress√£o se aproximam de zero. Como pode ser visto, selecionar um bom valor de Œª √© cr√≠tico. A valida√ß√£o cruzada √© √∫til para esse prop√≥sito. As estimativas dos coeficientes produzidas por este m√©todo s√£o tamb√©m conhecidas como norma L2.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*hAGhQehrqAmT1pvz3q4t8Q.png\" width=500>\n",
    "<br>\n",
    "Podemos ver esse problema da seguinte forma:\n",
    "<br>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*sC4KLMHU0j_1gR3VmlgGtg.png\" width=300>\n",
    "\n",
    "Os coeficientes que s√£o produzidos pelo m√©todo dos m√≠nimos quadrados padr√£o s√£o escala equivariante, ou seja, se multiplicarmos cada entrada por c, ent√£o os coeficientes correspondentes s√£o escalonados por um fator de 1 / c. Portanto, independentemente de como o preditor √© escalado, a multiplica√ß√£o de preditor e coeficiente permanece a mesma. No entanto, esse n√£o √© o caso da regress√£o de Ridge e, portanto, precisamos padronizar os preditores ou trazer os preditores para a mesma escala antes de executar a regress√£o de Ridge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cali_data = fetch_california_housing()\n",
    "cali_df = pd.DataFrame(cali_data.data , columns = cali_data.feature_names)\n",
    "cali_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add another column that contain the house prices which in sklearn are considered as target\n",
    "cali_df['Price'] = cali_data.target\n",
    "newX=cali_df.drop('Price' , axis =1)\n",
    "newY= cali_df['Price']\n",
    "\n",
    "X_train , X_test, y_train, y_test= train_test_split(newX,newY, test_size=0.33, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "rr = Ridge(alpha=0.01) \n",
    "# Quanto maior o valor Alpha, mais restrito ser√£o os coeficientes ; baixo alfa > maior generaliza√ß√£o\n",
    "rr.fit(X_train , y_train)\n",
    "rr100 = Ridge(alpha=100)\n",
    "rr100.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score=lr.score(X_train, y_train)\n",
    "test_score=lr.score(X_test, y_test)\n",
    "ridge_train_score = rr.score(X_train,y_train)\n",
    "ridge_test_score = rr.score(X_test, y_test)\n",
    "ridge_train_score100 = rr100.score(X_train,y_train)\n",
    "ridge_test_score100 = rr100.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Reg Train Score: 0.6082951018632644\n",
      "Linear Reg Test Score: 0.5964388657346261\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ridge Reg Train Score: 0.6082951018509163\n",
      "Ridge Reg Test Score: 0.5964397845945382\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ridge Reg 100 Train Score: 0.6075226508546894\n",
      "Ridge Reg 100 Test Score: 0.6023315731675578\n"
     ]
    }
   ],
   "source": [
    "print(f'Linear Reg Train Score: {train_score}')\n",
    "print(f'Linear Reg Test Score: {test_score}')\n",
    "print('-'*100)\n",
    "print(f'Ridge Reg Train Score: {ridge_train_score}')\n",
    "print(f'Ridge Reg Test Score: {ridge_test_score}')\n",
    "print('-'*100)\n",
    "print(f'Ridge Reg 100 Train Score: {ridge_train_score100}')\n",
    "print(f'Ridge Reg 100 Test Score: {ridge_test_score100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEOCAYAAACuOOGFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABAfUlEQVR4nO3deXhU1fnA8e+bhCyETEICCAUCkU1URAXUVtBoW3EBsSBWsURcahWtUEVFhYpiW1xrbRWqSDG4U+XnjtZdrBtIQUEEJCtrEgghIQnJ5P39cSchCTPJBCbMjHk/z3OfmXvumTtvhjBvzj3nniOqijHGGHOoIoIdgDHGmB8HSyjGGGMCwhKKMcaYgLCEYowxJiAsoRhjjAmIqGAHECydOnXS3r17BzsMY4wJKytWrChU1c7ejrXZhNK7d2+WL18e7DCMMSasiEiOr2N2ycsYY0xAWEIxxhgTEJZQjDHGBIQlFGOMMQHRZjvljTkU1TXVZBdnU1JZgivGRVpSGpERkcEOy5igsoRiTAsVlBWQuSqTovIiBEFRUuJSyBicQed4r6MpjWkT7JKXMS1QXVNN5qpMKt2VnFgQxeX3vsOJBVFUuivJXJWJu8Yd7BCNCRproRjTAtnF2RSVF/G7Wa+RsKWI6ph2nHnHfIb9JIV/zhpNVnEWfZP7BjtMY4LCWijGtEBJZQmC8NV1v6ImKpLyTonUREXy5fVjERFKKkuCHaIxQWMJxZgWcMW4UJSd/XqgIrTfUYyKsKtvd1QVV4wr2CEaEzR2ycuYFkhLSiMlLoXCvYXknzyQgmPT6PxtFoV7C0mJSyEtKS3YIRoTNJZQjGmByIhIMgZnkLkqk8UZQxAR9MRkUiJjyBicYUOHTZtmCcWYFuoc35kpp0yx+1CMacQSijEHISoiykZzGdOIdcobY4wJCEsoxhhjAiJkE4qIJIvIEhEpE5EcEZngo56IyD0isllEdovIhyJyzOGO1xhj2rqQTSjAo8A+4AjgUmCuj0QxHrgCGAEkA58Biw5XkMYYYxwhmVBEJB4YB8xU1VJVXQa8Ckz0Uj0NWKaqm1TVDTwNHH34ojXGGAMhmlCA/oBbVdfXK1sFeGuhPA/0FZH+ItIOuAxY6u2kInK1iCwXkeUFBQUBD9oYY9qyUB023AHY3ahsN5Dgpe5W4BPge8AN5AFnejupqj4OPA4wdOhQDVSwxhhjWtBCEZF4EblBRP4tIh+ISD9P+cUiclSA4yoFGk+K5AL2eKl7JzAM6AnEAncB74tI+wDHZIwxpgl+JRQR6QmsBu4H+gGnsb+1cAYwLcBxrQeiapOWx2BgjZe6g4EXVDVfVatVdSHQEetHMcaYw8rfFsqDQCVOMhkCSL1jH+EkmIBR1TLgZeBuT8voVGAM3kdvfQWMF5EjRCRCRCYC7YCNgYzJGGNM0/ztQ/klcLWq5opI4wmLNgPdAxsWAJOBBcAOoAi4VlXXiEgqsBY4WlVzgXuBLsD/gHicRDJOVYtbISZjjDE++JtQovHefwGQCFQFJpz9VHUncIGX8lycTvva/QrgOs9mjDEmSPy95LUa574Qb84BVgQmHGOMMeHK3xbK/cC/RQTgWU/Z0SIyBrgSOL8VYjPGGBNG/EooqvqyiEwG5uBMcwKQiXMZ7HpV9XojoTHGmLbD7xsbVXWeiCwCforTCV4E/FdVffWtGGOMaUNadKe8Zzjvu60UizHGmDDmM6GISIvuLVHVjw89HGOMMeGqqRbKh0DtfFdS77kvtqC2Mca0YU0llDPqPU8C/g58izO773acdUouwZkB2O4BMW3Ojh2QmQkZGdClS7CjMSb4fCYUVf2o9rmILATeUdWrGlXLFJEngbHAa60SoTEhaN8+mDsX1q6FsjK47TaIjg52VMYEl783No4BXvBx7AXPcWPajJdegqwsGDjQeXzppWBHZEzw+ZtQIoC+Po71w/pPTBuyciW8+Sb07Ons9+zp7K9cGdy4jAk2fxPKG8BfRGR87eSQIhIpIhcB9wCvt1aAxoSaF1+ExESI9PwZFRnp7L/4YnDjMibY/E0oNwDf4FzeKheR7UA5Tgf9N57jxrQJF10Eu3eD2+3su93O/kUXBTcuY4LN36lXCoERIvJL4BSgG87Su5+pqt3oaNqUE06Ac8+Ft9+G3r0hL8/ZP+GEYEdmTHC19E75/wD/aaVYjAkb48bB+vXOKK+jj3b2jWnr/F5T3hizX3Q0XHstDBvmPNqQYWP8bKGISA3N3CmvqjbSy7QpXbrAtGnBjsKY0OHvJa+7OTChpABnATHAwgDGZIwxJgz52yk/y1u5Zwjxa8DuAMZkjDEmDB1SH4qquoHHgKkBicYYY0zYCkSnfAyQHIDzNCAiySKyRETKRCRHRCY0UfdIEXldRPaISKGI3BfoeIwxxjTN3075VC/F0cCxOMsCLw9kUB6PAvtwZjU+HnhDRFap6ppGsUXjDGV+FPg14Ab6t0I8xhhjmuBvp3w23kd5CfADAZ6+XkTigXHAsapaCiwTkVeBicD0RtUnAVtU9aF6ZasDGY8xxpjm+ZtQruDAhFIB5ABfefpSAqk/4FbV9fXKVgGne6l7CpAtIm8Bw3DWbPm9qn7TuKKIXA1cDZCa6q3RZYwx5mD5O8prYSvH0VgHDhw5thtI8FK3B85iYOcD7wFTgFdE5ChV3Ve/oqo+DjwOMHTo0OZWoDTGGNMCfnXKi8gmERns49ixIrIpsGFRCrgalbmAPV7qlgPLVPUtTwJ5AOcemYEBjskYY0wT/B3l1RtnNJc3sUCvgESz33ogSkT61SsbDKzxUnc1za93b4wxppW1ZNiwry/toUDxoYdS741Uy4CXgbtFJF5ETsVZFXKRl+pPA6eIyC88N1pOBQqB7wIZkzHGmKb57EMRkT8Af/DsKvCaiOxrVC0O5x6U51shtsnAAmAHUARcq6prPEOY1wJHq2quqn4vIr8B5gFdgK+B8xv3nxhjjGldTXXKb8Lp5Aa4DOdek4JGdSpxvtznBzowVd0JXOClPBen075+2cs4LRpjjDFB4jOhqOorwCsAIgJwt6pmHaa4jDHGhBl/hw1f3tqBGGOMCW9N9aH8EZivqls8z5uiqjo7sKEZY4wJJ021UGYBS4EtnudNUcASijHGtGFN9aFEeHtujDHGeGOJwhhjTED4OzlkHRHpgnN3fAOe4bzGGGPaKH/XQ3EBf8NZb8TXFCyRgQrKGGNM+PG3hfIozvokTwLf4NzQaIwxxtTxN6GMBG5W1UdbMxhjjDHhy99OeQG+b81AjDHGhDd/WyjPA6OBd1sxlpBXXVNNdnE2JZUluGJcpCWlERlhXUfGGAP+J5R3gIdFJAF4E9jZuIKqvh/IwEJNQVkBmasyKSovQhAUJSUuhYzBGXSO7xzs8IwxJuj8TSiveB7TgEn1yhXncpjyIx7lVV1TTeaqTCrdlZxYEMXxC97if1ecw/rulWSuymTqKVOtpWKMafP8TShntGoUIS67OJui8iJ+N+s14vOLKK5qR/pt8xnWI4V/zhpNVnEWfZP7BjtMY4wJKn9nG/6otQMJZSWVJQjC57/7FcOm/YstMYlElO/iy2vGIlJNSWVJsEM0xpigs6lX/OCKcaEo/9nTgyq38JN9xVS5hXdLuqOquGJcwQ7RGGOCzt875ZvqcK8BdgMrgCdVdXsgAgslaUlpVOxMYcXaQlb3H8iGHmn0y89ixdpCzuiUQlpSWrBDNMaYoPO3D0WA/kA3IAvYDhyB00m/1bN/LvAHETldVde2QqxBExkRifvrDNrHZPLIL4cgCG8NTKZ9aQzurzOIHG8d8sYY429CeQh4GBiiqitrC0VkCPAicBdOC+Ud4E/ArwIbZvBNuqgzhQ9NISkum+rIEqLcLoq3pzHpRksmxhgD/veh3APMqp9MAFR1BU4yuUdV84H7gdMCG2JoOOEEGHVuFGV5fenGiZTl9WXUuZGccEKwIzPGmNDgb0LpDxT6OFYA1I6Z/QGIP9SgAEQkWUSWiEiZiOSIyAQ/XvO+iKiItHhafn+MGwdpafDdd87juHGt8S7GGBOe/E0o2cBVPo5d7TkO0AkoOrSQ6jwK7MPpq7kUmCsix/iqLCKXchDru7REdDRcey0MG+Y8Rke35rsZY0x48fcL+G7gaRFZDbwE7AC64ExpfyxQ23r4BfDFoQYlIvG151bVUmCZiLwKTASme6mfCNwJZACfHer7N6VLF5g2rTXfwRhjwpO/NzY+JyKFOP0ltwPtgCpgOXCWqtZOGnkj4A5AXP0Bt6qur1e2CjjdR/0/A3OBbU2dVESuxmlRkZqaGoAwjTHG1PL7EpGq/gf4j4hE4FzaKlTVmkZ1KgIUVwece1vq2w0kNK4oIkOBU4EpQI+mTqqqjwOPAwwdOlQDEqkxxhjgIPocPElkRyvEUl8p0Pj2cxewp36BJ7k9BkxR1WoRaeWwjDHG+OJ3QhGRaOAcYAAQ2+iwqursAMa1HogSkX6qusFTNhhY06ieCxgKvOBJJrU3heSLyHhV/SSAMRljjGmCv1Ov/ARYBvRm/5T1eJ7XClhCUdUyEXkZuFtErgKOB8YAP2tUdTfwk3r7PYEvgSE4w5mNMcYcJv4OG74f5ws6FSeZnAwciXNX/EbP80CbDMThXF57DrhWVdeISKqIlIpIqjq21W7sTyLbVXVfK8RkjDHGB38veY0ApgFbPPs1qpoN/FFEIoFHcFoQAaOqO4ELvJTn4nTae3tNNvtbT8YYYw4jf1soKcAWT4d8GdCx3rH3gfQAx2WMMSbM+JtQ8nGGCoMzvcpZ9Y6dBARquLAxxpgw5e8lrw9wbir8P+CfwKMicjzOzY0jPWXGGGPaMH8TygwgGUBV53omX/w10B64D2dqFmOMMW2Yv1OvFFJvtmFV/Tvw99YKyhhjTPixNeWNMcYEhM8Wioi05DKWquqdAYjHGGNMmGrqktcMGt4V3xTFmT7eGGNMG9XUJa8ynEka/wWcoaoRTWy2sLoxxrRxTSWUI4DrcaZbeVdEskTkbhHp28RrjDHGtFE+E4qq7lXVRar6SyAN516TscB6EflMRK4VkY6+Xm+MMaZt8WuUl6rmq+ocVT0WGAb8D2f+rvmtGJsxxpgw0qIFtkTkJJx13S/EuUt+ZWsEZYwxJvw0m1BEpBfwG5xE0h/4FGdd+RdVtfEyvcYYY9qopu5DuQoniZwKbAKeATJVNeswxWaMMSaMNNVCeRwoATJxVmsEOENEzvBWWVUXBDg2Y4wxYaS5S14uYJJna4oCllCMMaYNayqhpB22KIwxxoQ9nwlFVXMOZyDGGGPCm802bIwxJiBCNqGISLKILBGRMhHJEZEJPupdJiIrRKRERPJF5D7PAmDGGGMOo5BNKMCjwD6cOcUuBeaKyDFe6rUHpuKseX8y8HNg2mGK0RhjjEdI/iUvIvHAOOBYVS0FlonIqzj3xUyvX1dV59bb3SwizwBehzYbY4xpPaHaQukPuFV1fb2yVYC3FkpjpwFrvB0QkatFZLmILC8oKAhAmMYYY2r5lVBE5H0ROcrHsf4i8n5gw6ID0Hhal91AQlMvEpHLgaHAA96Oq+rjqjpUVYd27tw5IIEaY4xx+HvJKx3nJkdvEoDTAxLNfqVe3s8F7PH1AhG5AJgD/EJVCwMcjzHGmGa05JKX+ijvg5MAAmk9ECUi/eqVDcb3payzgSeA0ar6TYBjMcYY44emJoe8HLjcs6vA4yLSuIUQBxwLvBfIoFS1TEReBu72TFJ5PDAG+JmXOM/EmbjyV6r6ZSDjMMYY47+mWig1gNuzSaP92q0ImAtc2QqxTcZJWDuA54BrVXWNiKSKSKmIpHrqzQQSgTc95aUi8lYrxGOMMaYJTU298hTwFICIfIDzhb7ucAWmqjuBC7yU5+J02tfu2xBhY4wJAX51ytuXtjHGmOb4fWOjiLiAc4FUILbRYVXV2YEMzBhjTHjxK6GIyKnAa0CSjyoKWEIxxpg2zN9hww8D2cAwIFZVIxptka0VoDHGmPDg7yWvgcBFqrqiNYMxxhgTvvxtoeQCMa0ZiDHGmPDmb0K5C5ju6Zg3xhhjDuDvJa9ROOuSZInIZ8DORsdVVS8LaGTGGGPCir8JZTjOSK4SvE8h72ueL2OMMW2Evzc2prV2IMYYY8JbqC6wZYwxJsz4nVBEJF5EbhCRf4vIB7VTy4vIxb4W3zLGGNN2+HunfE/gQ6AHsA5nyvra1RPPAH4BXNUK8RljjAkT/rZQHgQqgX7AEJzp7Gt9hLOOuzHGmDbM31FevwSuVtVcEWk8zcpmoHtgwzLGGBNu/G2hRON7PfdEoCow4RhjjAlX/iaU1cA4H8fOAWyOL2OMaeP8veR1P/BvEQF41lN2tIiMwVn+9/xWiM0YY0wY8auFoqov46zxPh5411OcCUwFrlfVpa0SnTkk1TXVfLFhI1Pv/ZovNmzEXeMOdkjGmB8xv1dsVNV5IrII+CnQBSgC/quqvvpWTBAVlBWw4OtMXn+/iMICYcWzyqgzU7jixAw6x3cOdnjmMKquqWbFD9k893IJl4x1MbRPGpERtoSRCbwW3SmvqmWq+q6qPquqb7dmMhGRZBFZIiJlIpIjIhOaqPsHEdkmIrtFZIGItOmp9qtrqslclcnXqyrpvS6Kf37wDr3XRfH1qkoyV2VaS6UNKSgr4MFP/8a0Zxfwdt5LTHt2AQ98+jAFZQXBDs0na1mHL58tFBE5DfhaVUs9z5ukqh8HNDJ4FNiHM8vx8cAbIrJKVdc0inMkMB04E9gCLMEz3X6A4wkb2cXZrMkq4vcPvEbPsiL2tWvHPe/OJ++zFBb8aTRZR2XRN7lvsMM0razxHxZ/Wv0WTxx3Dl+nVBIVmcnUU6aGXEvFWtbhTVS9TxQsIjXAKar6pee5rxmFBWf6+oD9ZopIPLALOFZV13vKFgGbVXV6o7rPAtmqertn/+fAM6ratan3GDp0qC5fvjxQIYeUr7d+zfWPvcTA3EjuePtfFCZ2pNPuXdwz8grWpVbzj8njOLHbicEO03hRU1NDfn4+ZWVlh3yuqpoqSspLOeqGW4jbtoWamBgiKisp7/oT1j1yH664DrSLaBeAqANDVdmzbw+V+5TY736g96KFZE+cRMXAPsRECwnRCXgGBplW1K5dO7p06YLL5X35KxFZoapDvR1rqg/lDGBtveeHU3/AXZtMPFYBp3upewzwSqN6R4hIiqoW1a8oIlcDVwOkpqYGNuIQ4opxcdRRypqdPahBSC4ppgZhbYfuHH1UNq4YWyctVBUWFiIiDBgwgIiIQ5u7tWxfGbkFxZTOuocOf7ge/Ul3IrdsZs9dfyKlWy9SOycRHx0foMgPXUV1Bdt2F5Iy/nKiN+dRExvL4D/PZl/3nhQt/hddEzsRGxUb7DB/1FSV8vJyNm/eDOAzqfjiM6Go6kfenh8mHYDdjcp2s3/+sKbq1j5PwBk4UEdVHwceB6eFEpBIQ1BaUhrHpKVQtquQz7oPJK9vGj03ZtFrYCHHpKWQlmSrEYSq4uJievfufcjJBCAyIpK4WKV8wDEQEUHUtq0QEUFF/6OJi60Muctd7ho35RVC0fQ76PqH63F3OQLZspnC22ZQUSG4E6wvpbWJCO3bt6d79+5s2bIlcAml0Zv0B7p5Syye/pWtqrqhRe/ctFKg8U/iwvvd+o3r1j5vs6PPIiMiyRicQbU7k8fPH0JRgZBydDKjBseQMTgj5L5IzH5ut5t27QJzGSomMobYmCjc7mpKh5/OviEnEr3ia6LjqomNiSImMrTGroRbAvwxi4uLo6qq5ROg+Dts+GGcy1/eWiqjgKM9j4GyHogSkX71EtVgYI2Xums8x16sV29748tdbU3n+M7cdOoU0rvacNFwE6h+AhEhJS4F1SIKZ95KdbUQde4vSYxzykOtPyLcEuCP2cH+bvibUIYC83wc+xgI6HryqlomIi8Dd4vIVTijvMYAP/NSPRNYKCLPAFuBGcDCQMYTrqIioji5X19OvjXYkZhgaRfZjq4djiChXSU7d7lJ7hhJfExMyCUTCL8EaA7kb0JJACp8HKvCmSAy0CYDC4AdOH0h16rqGhFJxWktHa2quaq6VETuAz4A4oCXgDtbIR5jwpKI0CE2lg7dgh1J88IpAZoD+ZtQNgE/B97xcuxMIDtQAdVS1Z3ABV7Kc3E64uuXPQQ8FOgYjDGHXzglQNOQv0NJMoE/iMh1tXehi0iMiFyHM5/XU60UnzEmjJ1zzjncd999Xo/l5+cjImRnZx/eoEyr8TehPAC8CvwdKBORHUCZZ/9V4N7WCc8YE6rS09OJiYmhQ4cOJCYmcvzxx7N48eIGdd566y1uueWWIEUYHG63m5tvvpnOnTuTkJDAuHHjKCwsPOj6zz//PCNGjMDlchEV5ff0i0Hh72zDblW9EGft+PuB/wPuA85U1fGqWtN6IRpjQtXMmTMpLS2lqKiISZMmMWHCBDZu3BjssIJqzpw5vPLKK3zxxRfk5+cDMHHixIOu37FjRyZPnszDDz/cqnEHhKq2yW3IkCFqTKhZu3btoZ9k1SrViy5yHlvR6aefrrNnz67bLy0tVUAXL17stc7WrVt19OjR6nK5tF+/fvrEE08ooFlZWXXHR40aVXd8/vz5DY6rqpaVlelNN92kvXv31o4dO+rIkSN1w4YNdcf/8pe/6KBBg5qMe9GiRTpo0CBNSEjQkSNHanFxsR555JG6cePGAHwqqqmpqTp//vy6/Y0bNx7wcxxM/Q8++EAjIyMDEqM/fP0uAsvVx/fqod+Oa4wJHaNGwSWXwA8/OI+jAnl7mG/79u1j7ty5APTv399rnUsvvZTIyEhyc3P5+OOPWbhw4QHHo6OjycvLY9myZSxatOiAc1x11VWsW7eOzz//nG3btnHyySczatSoupvwpk+fzurVq33GOW/ePGbMmMHzzz/P5s2b2bhxI+PHj+e8886jT58+DepOnjyZpKQkn9ucOXMOOP/u3bvJzc1lyJAhdWV9+vTB5XJ5jaul9UOer0wDuIGTPM9rPPu+tmpf5wnVzVooJhQdcgtl1SrVwYNVR41yHlevDkRYXp1++ukaGxuriYmJGhERoTExMQ3+0q6tM3v2bM3Pz1egQSvgnXfeqftLPC8vTwH94Ycf6o6/++67Df5SLygoUEBzcnLq6rjdbnW5XPrJJ580G29VVZWmpKTokiVL6srGjh2rCQkJumPHjoP8FBrKzc1VQDdt2tSgPDU1VRctWnRI9cOhhdJUD8/dQH695z/aua9MaNixAzIzISMDunQJdjRh6rjjICICNm92HgcNatW3u+OOO5gxYwa7du3iyiuv5P333+fKK688oF5t30CvXr3qytLS9s8pVzsZYf1JW+vXBcjKygLguOOOa1BeVVVFXl5es7EuW7aM8vJyzjvvvLqy6upqbrzxRjp3DszU+AkJznSDu3c3nIqwuLjY67xYLa0f6ppKKCtxRnKhqrMOSzSmzdq3D+bOhbVroawMbrsNoqODHVWYOussOOkk+PLLw/aWHTt2ZP78+fTp04dXXnmFMWPGNDjevXt3AHJycuouLdUmiPrHc3NzOfLII+ue11ebYDZs2HBQCSAvL4+uXbvWzZW2YcMGli5dSkZGhtf611xzDU8//bTP891+++3cfvvtDcqSkpJITU3l66+/5vjjjwdg06ZNlJSUHJAID6Z+qGuqD2UJMABARNwictLhCcm0RS+9BFlZMHCg8/jSS8GOKIzNmQNjxzqPh1FycjI33ngjt99+OzU1DQd+9ujRg/T0dG655RZKSkrYvn07s2fPPuD49OnT2bNnDzt27OCee+5pcI4uXbowYcIEJk+eXNeiKS4uZsmSJZSWlgIwa9Ysevfu7TW+nj17kpOTw8qVK9m5cycTJ04kOTnZZ+tm3rx5lJaW+twaJ5NaV199Nffeey9ZWVmUlJRw6623MnLkSJ9xNVff7XZTUVHBvn37AKioqKCioqK2ayKkNJVQStk/pYrNe2BazcqV8Oab0LOns9+zp7O/cmVw4zItN2XKFLZu3UpmZuYBx5599lkqKyvp2bMnI0aMOKBl8Oyzz7J371569OjB8OHDGT9+PAAxMfsnhXziiScYMGAA6enpJCQkMGjQIBYvXlw3NUtubi7p6eleYzvttNO47rrrGDlyJH369GHcuHE88sgjzJw5kxdeeCFAn4AzMGD06NEMGzaM7t2743a7G7R0rrnmGs455xy/6y9atIi4uDhGjhyJ2+0mLi6OuLg4cnJyAhZzoDS1YuP7QG+cyR8zgDcAXwtRq6oeeOE0hP2YV2wMN7fdBnv2QKdO+8sKCyEhAf7yl+DFFQzfffcdAwcODHYYIeHtt99mzJgxlJeX+z2XV//+/XnvvffoWfvXiTlovn4XD3bFxmuBvwKn4XTIn4Szxrs3odf2MmHjoovggYeq0Y7ZVEeWEOV2Ubw7jSuvtKn225JVq1YhIgwaNIisrCxmzJjBr3/96xZNDLl+/frmK5lW09SKjd8D50Ld+vKjVfXw9fKZNqNH/wLklEw+3lBEUpJQvEcZfEoKPfpnAIEZfWNC386dO/ntb3/L1q1bSUxM5JxzzuHBBx8MdlimBXz2oYjIyyLS17N7Oc5aI8YEVHVNNZmrMhlwdCXplVHMXPQO6ZVRDDi6ksxVmbhrbNnXtuKMM85g48aNlJWVsWXLFp588kmSkpKCHZZpgaY65ccAKZ7nCwCbTNoEXHZxNkXlRWT88TnuXDqfIyt3cOfS+WT88TmKyovIKs5q/iTGmJDQVELZDpzieS5YP4lpBSWVJQjCV9f9CqIjaXdkIkRH8uX1YxERSipLgh2iMcZPTSWUF4G/iogbJ5l87rkfxdtWfXjCNT82rhgXirKzXw9UhPY7ilERdvXtjqriigm/u4WNaauaGuX1B+BT4GicJXUXApsPQ0ymDUlLSiMlLoXCvYXknzyQgmPT6PxtFoV7C0mJSyEtKa35kxhjQkJTo7wUWAwgIpOAv6nqqsMUl2kjIiMiyRicQeaqTBZnDEFE0BOTSYmMIWNwBpERNnTYmHDh1/Jfqmp/JppW0zm+M1NOmUJ2cTYllSW4YlykJaVZMjEmzPi9nqSIdAduwrnRMRk4X1W/FZGpwGeq+kXrhGjagqiIKPom922+ojEmZPm1wJaIHAN8A0wEtgC9gNq5YHsBUwIVkIgki8gSESkTkRwRmdBE3ctEZIWIlIhIvojcJyKhveiyMcb8SPm7YuODwHdAGjCWhpNF/pf9w4sD4VGcKV6OAC4F5noSmjftgalAJ+Bk4OfAtADGYowxxk/+JpThwBxVLeXA+1G2A10DEYyIxAPjgJmqWqqqy4BXcVpGB1DVuar6iaruU9XNwDPAqYGIxRhz6M455xzuu+8+r8fy8/MREbKzsw9vUKbV+JtQapo41gkoD0AsAP0Bt6rWn+FtFeCrhdLYacAaXwdF5GoRWS4iywsKfE2cbEx427EDHnjAeWxN6enpxMTE0KFDBxITEzn++ONZvHhxgzpvvfUWt9xyS+sGEmKef/55RowYgcvlIirqwCvwbrebm2++mc6dO5OQkMC4ceMoLCz0+3go8zehfIkzn5c3F+HcrxIIHYDdjcp2AwnNvVBELgeGAg/4qqOqj6vqUFUdGqglP40JJbUrX371lfO4z9f84AEyc+ZMSktLKSoqYtKkSUyYMIGNGze27puGuI4dOzJ58mQefvhhr8fnzJnDK6+8whdffFG3NPLEiRP9Ph7K/E0os4HRIvIOzuUnBX4hIk8BvwL+5M9JRORDEVEf2zKcRb0a3xrtAvY0c94LgDnAOaoaHqncmFYQrJUvo6Ki+O1vf0t1dTX/+9//6srT09PrVl7ctm0b559/PomJifTv35+lS5c2OMe2bdsYPXp03fEnn3zygEtie/fuZdq0aaSlpZGcnMzZZ5/dIIHNmTOn2aVzn376aY477jhcLhdnn302u3fvpk+fPvzwww+H/kEAI0eO5JJLLqlbyrixxx9/nFtvvZUjjzySxMRE7rvvPpYuXVr3czZ3PJT5lVBU9SPgApxO+QU4nfJzgBHABf4OGVbVdFUVH9twYD0QJSL96r1sME1fxjobeAJnev1v/InDmB+jYK58uW/fPubOnQs4i1x5c+mllxIZGUlubi4ff/wxCxcuPOB4dHQ0eXl5LFu2jEWLFh1wjquuuop169bx+eefs23bNk4++WRGjRpFVVUV4Kx+uHr1ap9xzps3jxkzZvD888+zefNmNm7cyPjx4znvvPPq1rqvNXnyZJKSknxucw5iieXdu3eTm5vLkCFD6sr69OmDy+Vi9erVzR4Pearaog3oC/wMGNDS1/p5/ueB54B4nA723cAxPuqeCRQBp7X0fYYMGaLGhJq1a9ce9GunT1e97jrVO+/cv113nVPeGk4//XSNjY3VxMREjYiI0JiYGJ0/f/4BdWbPnq35+fkK6MaNG+uOvfPOOwpoVlaW5uXlKaA//PBD3fF333237riqakFBgQKak5NTV8ftdqvL5dJPPvmk2Xirqqo0JSVFlyxZUlc2duxYTUhI0B07dhzkp+DbBx98oJGRkQ3KcnNzFdBNmzY1KE9NTdVFixY1e/xw8vW7CCxXH9+r/l7yqp+ANqrqf9VZgKs1TAbigB04ieVaVV0DICKpIlIqIqmeujNx1r1/01NeKiJvtVJcxoS0iy6C3bvB7VlCxu129i+6qPXe84477qC4uJjCwkLOPfdc3n//fa/1avsCevXqVVeWlrZ/Ao7Nm51pAlNTU+vK6tcFyMpyljI47rjj6loJycnJVFVVkZeX12ysy5Yto7y8nPPOO6+urLq6mhtvvJHD1aeakOB0B+/e3bCruLi4GJfL1ezxUOd3QhGRQSLybxEpEJFqEdkhIi+KyKBABqSqO1X1AlWNV9VUVX223rFcVe2gqrme/TNUNcpTVrudE8h4jAkXJ5wA554Ltd+teXnO/gkntP57d+zYkfnz5/Pmm2/yyiuvHHC8e/fuAOTk5NSV1SaI+sdzc3Pryuo/h/0JZsOGDRQXF9dte/fu5ZJLLmk2xry8PLp27Uq7du3qzrN06VIGDfL+FXbNNdfQoUMHn9uf//znZt+zsaSkJFJTU/n666/ryjZt2kRJSUldomzqeKjz9075YcAXwBnA68D9wBs4l5w+F5EhTbzcGHOYjBsHaWnw3XfO47hxh++9k5OTufHGG7n99tupqWl4p0GPHj1IT0/nlltuoaSkhO3btzN79uwDjk+fPp09e/awY8eOus78Wl26dGHChAlMnjy5rkVTXFzMkiVLKC0tBWDWrFn07t3ba3w9e/YkJyeHlStXsnPnTiZOnEhycrLP1s28efMoLS31ud1+++1eX+d2u6moqGCfZ4hdRUUFFRUVtZfpufrqq7n33nvJysqipKSEW2+9lZEjR9bF3dzxUOZvC+UvwLdAb1W9XFVvU9XLcTrpv/UcN8YEWXQ0XHstDBvmPEZHN/+aQJoyZQpbt24lMzPzgGPPPvsslZWV9OzZkxEjRpCRkXHA8b1799KjRw+GDx/O+PHjAYiJiamr88QTTzBgwADS09NJSEhg0KBBLF68GBFn8o7c3FzS09O9xnbaaadx3XXXMXLkSPr06cO4ceN45JFHmDlzJi+88EKAPgFYtGgRcXFxjBw5ErfbTVxcHHFxcXWts+nTpzN69GiGDRtG9+7dcbvdPP3003Wvb+54KJParNlkJZFSYKKqLvFybCzwlKo2e69IKBk6dKguX7482GEY08B3333HwIEDgx1GSHj77bcZM2YM5eXldQmjOf379+e9996jZ+1QN3PQfP0uisgKVR3q7TX+TqTYXNax5YGNMYdk1apViAiDBg0iKyuLGTNm8Otf/9rvZAKwfv365iuZVuPvJa8vgNtFpEErxDP31q3A54EOzBjTtuzcuZOxY8fSoUMHhg8fznHHHcff/va3YIdlWsDfFsrtwIdAjoi8DmzFmRDyPJwhvumtEZwxpu0444wz2vy0LeHO3xUbvxSRU4A/AiNxFtjaCbwPzFa7Q90YY9o8vxejUtXVwIWtGIsxxpgw5rMPRUQiRGS0iBzbRJ1BIjK6dUIzxhgTTprqlP8NztQnZU3U2QM8JyLN36ZqjDHmR625hPIvVc3yVUFVs4EngcsCHJcxxpgw01RCORF4x49zvIuzsJUxxpg2rKmEkgDs8uMcu/BjRUVjjDE/bk0llEKgVxPHa6V66hpjjGnDmkooy/Cvb2SSp64xxnDNNddw/fXXBzuMH7VQ/Yybug/lYWCZiPwVuFVV99U/KCLtgAdwprAf3moRGmP8Vl1TTXZxNiWVJbhiXKQlpREZERnw90lPT+cXv/gFM2bMOODYvHnzAv5+hyo7O5u0tDTat2+PiNC+fXtOPfVUHnrooQYLfYWLUPyMoYmEoqqfichNwIPApSLyDlC7Ok4v4JdACnCTqtpcXsYEWUFZAZmrMikqL0IQFCUlLoWMwRl0jj88KxKGgqqqqrpFtBr7/vvv6dGjBwUFBVx00UVcfvnlfPjhh4c9jh+rJieHVNWHcRbVWg78CrjNs/3KU3aGqtrsbcYEWXVNNZmrMql0V9I7qTe9knrRO6k3le5KMldl4q5xH7ZYJk2axFVXXVW3LyI89thjDBs2jISEBE455RTWrVu3P/bqav785z/Tv39/kpKSOPXUU1mxYkXd8ffee4+TTz6Zjh070rlzZy6++GJ27NhRdzw9PZ2pU6dywQUX4HK5ePDBB5uNsXPnzlx44YXUX8Ji7969TJs2jbS0NJKTkzn77LMbzC22Z88eMjIySE5OplevXmRmZhIVFVWXkGbNmsWZZ57JtGnTOOKIIzj//PMB+OSTTxg+fDjJycn06dOHBx98sG6xrV27djF+/HhSUlJITEzk2GOP5ZNPPgFg5cqVDB8+nMTERJKTk/nZz37Grl27vH7GOTk5jBkzhk6dOtGzZ0+mTp1KeXm53/8GgdLsbMOq+rGqnoszkqurZ3Op6nmq+knAIzLGtFh2cTZF5UV0at+pQXmn9p0oKi8iq9jn7WSHxcKFC3nppZcoLCykZ8+e/P73v6879sc//pFXXnmFpUuXUlRUxBVXXMHIkSPrvjxjYmL4xz/+QUFBAd988w1btmxhypQpDc6/YMECbrjhBnbv3s0NN9zQbDzbtm3jhRdeYMCAAXVlV111FevWrePzzz9n27ZtnHzyyYwaNYqqqirAWTxs06ZNrFu3jm+++YY33ngDt7thov7444/p1q0beXl5vPTSS6xZs4Zzzz2Xm2++mYKCAt544w3+8Y9/sGjRIgDuv/9+9u7dS05ODsXFxbz88sv06NEDgOuuu46zzjqLnTt3sn37dh566CGivayYVl1dzXnnnUfXrl3Jycnh888/59NPP2XatGl+/xsEit9ryqtqjaru8GyH788dY0yzSipLELyvGyIilFSWHOaIGrr55ptJTU0lJiaGSZMm1bUMVJW///3v3H///Rx55JFERkZy5ZVX0q1bN9544w0Ahg8fzrBhw4iKiqJr167ccsstvPfeew3Of+GFF3LmmWfW9Y/4cswxx5CQkEC3bt3YtWsXzz77LACFhYU899xzPPbYYxxxxBFER0dz5513snXrVr744gtqamp45plnuPvuu+nSpQsul8vrmvKpqancdNNNREdH0759e+bOncv48eMZM2YMkZGRHHXUUVx//fV1K1pGR0dTVFTE999/j6rSv3//uj6d6OhocnNzycvLo127dpxyyinEx8cf8J5ffvklGzZs4KGHHiI+Pp7u3btzzz33sGDBAuovoOjr3yCQ/E4oh4uIJIvIEhEpE5EcEZng5+veFxEVEb8nvDTmx8IV40J9rHOnqrhiXIc5ooa6detW9zw+Pp49e/YAzhd5aWkpo0ePJikpqW7btGkT+fn5AKxYsYKRI0fStWtXXC4Xl1xyCQUFBQ3O7+9662vWrGHPnj189dVX7Ny5k02bNgGQleW04I477ri6GJKTk6mqqiIvL4+CggL27dtHr17776So/9xXHFlZWTz33HMNfra77rqLrVu3As6X/M9//nMuu+wyOnfuzGWXXcb27dsB+Ne//kVNTQ3Dhw8nLS2NmTNnUl1dfcB75uXl0aVLlwbJpk+fPlRUVDT4nHz9GwRSyCUU4FFgH3AEcCkwV0SOaeoFInIpLZg52Zgfm7SkNFLiUijc2/CWsMK9haTEpZCWFJojmTp16kR8fDzvvvsuxcXFdVtZWRnTp08H4OKLL+bEE09k/fr1lJSU8Nxzzx1wnoiIln2VDR06lHvuuYff/va37N27ty45bNiwoUEce/fu5ZJLLqFz585ER0fXrQsPzvr1zcXRq1cvrrjiigbnLCkpYc2aNYDzxf6nP/2Jb7/9ljVr1rB582ZuvvlmANLS0liwYAH5+fm8+uqrzJ8/v65lU1/Pnj3ZsWMHe/furSvbtGkTsbGxdOrU6YD6rSmkEopnBchxwExVLVXVZcCrwMQmXpMI3AnccniiNCb0REZEkjE4g5jIGLKLs8nZnUN2cTYxkTFkDM5olaHD1dXVVFRUNNhaSkSYMmUK06ZNY8OGDQCUlpby9ttvs2XLFgBKSkpITEwkISGB3Nxc5syZE5D4MzIyiI+P55FHHqFLly5MmDCByZMns3nzZgCKi4tZsmQJpaWlREREMGHCBGbNmkVBQQF79uzhjjvuAKB83z5yt5axz0vrYfLkyTz//PO89tprVFVVUV1dzdq1a/noo48AeO211/juu+9wu9106NCB2NhYoqKcv42feuqpus8gKSmJqKioumP1nXTSSfTt25ebbrqJvXv3smXLFmbOnMnll1/e4kR7qEIqoQD9Abeq1l8YehXQVAvlz8BcYFtzJxeRq0VkuYgsb9xkNibcdY7vzJRTpnDFCVcwbuA4rjjhCqaeMrXVhgzfddddxMXFNdi2bWv2v6HX84wZM4YxY8bgcrno168f8+bNo6amBoDHH3+c+fPnk5CQwNixYxk/fnxA4o+MjGTmzJnce++97Nq1iyeeeIIBAwaQnp5OQkICgwYNYvHixXVr2v/tb38jNTWV/v37c+yxx3Lmz50+m+KKckqqiikp30ulex9V7qq69zj22GN5/fXXefjhh+nWrRtdunRh0qRJdZeifvjhB0aPHo3L5aJ3797ExcXVJcz333+fIUOG0KFDB376058yYcIELr300gN+jqioKF5//XXy8/NJTU3lpJNO4uSTT+aBBx7w+nNXVcHOnQH5CA8g9Tttgk1ERgCLVbVrvbLfApeqarqX+kOB+TiTU/YAsoB2qnrgnwqNDB06VFujU8qYQ/Hdd98xcODAYIdhmqGqfLryU0YMGcFXz/ybAc8vouC6qegJA4hvLxwRf0RdIgol7hpl87ZKKirdxMZE0qNrDBER3uP09bsoIitU1euEwIe1hSIiH3o6zr1ty4BSoHHvoQtn3ZXG54oAHgOm+JNAjDHmUGRlZfHf//4Xt9tN7pZcZt76Rz5OTGLQXXcQlZNN9xuuocvFGVRUVlPprgx2uAeocleRU7idPdWF1MQUs6e6kOzC7Q1aVIfqsCYUVU1XVfGxDQfWA1Ei0q/eywYDa7yczoXTMnlBRLYBX3nK8z0tHWOMCZjy8nKuvvpqEhMTGXrCUKKj42j/2BNoVBTuLkegUVEU3jaD8go5rDeS+kNV2ba7iIoKpcP3G+l+zXV0+H4jFRVOeaCuVIXUyChVLRORl4G7ReQq4HhgDPAzL9V3Az+pt98T+BIYAlgHiTEmoI4++mi+/fZbACqqK9i2u5Dy0hiIiCBq21aIiKCi/9HExVa2yiCIQ1HprqS0vJrUyy+nXX4eNbGxdL3+Gqp69CQv819UuiqJjYo95PcJtU55gMlAHLADZwnia1V1DYCIpIpIqYikqmNb7cb+JLK98USWxhgTSDGRMcTGRBEdV03p8NPZOeUPlA4/nei4amJjooiJjAl2iA24a9zExQo7br6jQYtqxy0ziIsNXIsqpFooAKq6E7jAx7FcoIOPY9ng41ZhY8KIqoZkh67ZT0RIiUtBtYjCmbdSXS1EnftLEuOc8lD794uMiCSqnVJ94jGoOC0qlQgiTjiaqHYHtqhqR9i1VMglFGPastjYWIqKikhJCb0vJdNQu8h2dO1wBAntKtm5y01yx0jiY2JC8t8tJjKGqIgoImKrKT/9dMqOO5H41V8THVtNRMT+FpWqUlVVxfbt271O89KckBo2fDjZsGETiqqqqsjPzz+omwSNaYq7xk1ZVRnVbjdVVUK7dkpUZCTx7eIbtFCioqJITEykU6dOXm+MbGrYsLVQjAkh7dq1C8sFn0x4aO0F2CyhGGNMGxEVEUXf5L6tdv5QHOVljDEmDFlCMcYYExCWUIwxxgSEJRRjjDEB0WaHDYtIAZDTbEXvOgGFzdYKHeEUbzjFCuEVbzjFCuEVbzjFCocWby9V9bomQptNKIdCRJb7GocdisIp3nCKFcIr3nCKFcIr3nCKFVovXrvkZYwxJiAsoRhjjAkISygH5/FgB9BC4RRvOMUK4RVvOMUK4RVvOMUKrRSv9aEYY4wJCGuhGGOMCQhLKMYYYwLCEooxxpiAsITSAiKSLCJLRKRMRHJEZEKwY/JFRK4XkeUiUikiC4MdT1NEJEZEnvR8pntEZKWInBPsuJoiIk+LyFYRKRGR9SJyVbBjao6I9BORChF5OtixNEVEPvTEWerZvg92TE0RkYtF5DvP98IPIjIi2DF5U+/zrN3cIvL3QL6HTV/fMo8C+4AjgOOBN0RkVe2a9yFmC3APMBKIC3IszYkC8oDTgVzgXOBFERnkWdo5FP0FuFJVK0XkKOBDEVmpqiuCHVgTHgW+CnYQfrpeVecHO4jmiMgvgXuBXwNfAt2CG5Fvqlq3fLqIxAPbgcWBfA9rofjJ8w8wDpipqqWqugx4FZgY3Mi8U9WXVfX/gKJgx9IcVS1T1Vmqmq2qNar6OpAFDAl2bL6o6hpVrazd9Wx9ghhSk0TkYqAYeC/IofzY3AXcraqfe353N6vq5mAH5YcLgR3AJ4E8qSUU//UH3Kq6vl7ZKuCYIMXzoyUiR+B83qHY8qsjIo+JyF5gHbAVeDPIIXklIi7gbuCmYMfSAn8RkUIR+VRE0oMdjDciEgkMBTqLyEYRyReRf4hIqF8RALgMyNQA3zdiCcV/HYDdjcp2AwlBiOVHS0TaAc8AT6nqumDH0xRVnYzz7z8CeBmobPoVQTMbeFJV84IdiJ9uBY4EuuPcgPeaiIRi6+8IoB3OX/sjcC6DnwDMCGJMzRKRVJzLy08F+tyWUPxXCrgalbmAPUGI5UdJRCKARTj9VNcHORy/qKrbc/mzB3BtsONpTESOB34B/DXIofhNVb9Q1T2qWqmqTwGf4vSrhZpyz+PfVXWrqhYCDxGasdaXASxT1axAn9g65f23HogSkX6qusFTNpgQvywTLkREgCdx/uo7V1WrghxSS0URmn0o6UBvINf5iOkARIrI0ap6YhDjagkFJNhBNKaqu0QkHye+cJIBzGmNE1sLxU+qWoZzWeNuEYkXkVOBMTh/UYccEYkSkVggEucLJFZEQvkPiLnAQGC0qpY3VzmYRKSLZ6hoBxGJFJGRwCXA+8GOzYvHcRLd8Z5tHvAGzui/kCMiSSIysvb3VUQuBU4D3g52bD78C/i953eiIzAVeD24IfkmIj/DuZQY0NFdtUL5CyYUTQYW4IyOKAKuDdEhw+Bcx72z3v5vcEakzApKNE0QkV7A73D6ILZ5/pIG+J2qPhO0wHxTnMtb83D+KMsBpqrqK0GNygtV3Qvsrd0XkVKgQlULghdVk9rhDHc/CnDjDHi4QFVD9V6U2TiLVa0HKoAXgT8FNaKmXQa8rKqtcqneJoc0xhgTEHbJyxhjTEBYQjHGGBMQllCMMcYEhCUUY4wxAWEJxRhjTEBYQjHGGBMQllBMyBGRn4rIiyKyRUT2iUiRiPxHRC7zTMjXGu8ZISIPe9Y4qRGR//OUHyUi73vWPVERuUBEZolIi8bbi0i65/XprRB+7XtMEpEr/Kzb2xNPwNZxOZjPxfy42I2NJqSIyFSc+ZDex5kkMAfoCJyFczd9MdAaNxBeCEzBmZH3M/ZP+/8QzkSFF3ne+3tgObC0hef/GvgpsDYAsfoyCef/9IJWfA9jfLKEYkKGiJyG8wX+D1W9odHhV0TkISC+ld5+oOfxYVWtaVT+sarWTyC7gPyWnFxVS4DPDy1EY0KbXfIyoWQ6sBO4xdtBVf1BVVfX7ovISSLyrmc50zIReU9ETmr8OhE53XNsj6fe2yJybL3j2eyfksbtuRQ0yXP5pjcw0VOmnvoHXNrxzDt1q4is9SxfWyAiSz2rOfq85CUiY0XkcxHZKyLFIrLYM714/TrZ4iw5XH+p2eUiMrxenQ9xpiQ/tTZWT5nfan8ucZYKfsPzueaIyB89M0HXr3uCiHzi+Vk3i8hMvEzg6PlcbhORdeIsR71FRB70zDNXe6nxQ8/PmFjvdYNEpFxE7m/Jz2CCyxKKCQmevpF04B1VrfCj/nHARziXwybhzKDqAj4SkcH16p2Hs0phKc58ZhNw1jD5RER6eqr9Cljoef5Tz/aB57EAZ+Gs2nJfnseZw+lN4ALgtziXt3wuCSsi1wAveepdiDOf2bGen6HxOjsjcC7HzcRZbjYSeF1EkjzHJwMrgdX1Yp3cRLxNWYJzyfEC4P9w5oC7rF7cnTzHO3nKrwPOBrz13zyNM6/cs8B5eJZOxlnzBk9r8Dc4/yb/9Jw/DufzXAPccZA/gwkGVbXNtqBvONPWK/AXP+v/G6dPI6lemQunhfNyvbKNwHuNXusCCnEub9WW3eP8dzjgffKBhY3KZtWvC5zpif2GJuJN99RJ9+zXLti2oFG93jjrwUytV5aNc5mtY72yoZ7zTahX9iHOOhf+fH69Pa+/qvHPBVzeqO43OIm+dv9PnhhT65XFez7T+p/LCM/5Mhqd71JP+fH1yn5V+944MySXAv2D/XtpW8s2a6GYcHUa8LqqFtcWqNNP8SrOpR9EpB/O1O3PeC69RIkzhf9enI730wIUy1k4X4ZPtOA1P8VJbI1jy8eZYbdxbJ+p6q56+994HlMJvDca7X/b6H1+Cnyuqrm1Beos7/Bao9edjZN4Xmr0M77jOX5avdcvwWmhzMVp3f1eGy63bcKAJRQTKopwVsDr5Wf9ZJx13BvbhnMZDKCL5/FJoKrRNgpIOdhgG0kBdmrL1nGpje1dL7EN8hLbzvo7qlq73HBsi6Nt3s5G+5WN3qcbsN3L6xqXdQGicVob9X++HZ7jjX/Gp4AYz/FnWxy1CTob5WVCgqpWezqRfykiMfW+MH3ZCXT1Ut6V/V+ItUN/b8P54m5s38HE6kUhkCwicS1IKrWxTcL7qp+hvLT0VpxLlI01LivCWSNkhI/zbKl9IiLtcYY7fwv0w1lR8A+HHKk5rCyhmFAyB6cf4H6g8bBhRCQNSFBnpNdHwHkikqCexYI8HdmjPecA556RbOAYVW2VJU893sEZoXYV8Hc/X/NfnKTRV5110wOhEqdzu7V9BtwsIj1VNQ9AROJxPvv6luLcS5Soqu81c86/4awkeDxO6/FhEXlbGw7XNiHOEooJGar6sYjcCDwkIgNxRl7l4lzC+jnOF/YEnJFMs3G+eN4TkXtx+jBuBdoDd3vOpyJyHc49LNE4q+kV4vwl/TMgV1UfCkDcH4jIS564e+KMgGqH00fwhqp+6OU1JSJyM/CoiHQG3sLppO+O0wf0oaq29LLPWmCyiPwa+AHYo62z0uFfcUaQvSMis3AS2c04lyzrqOqHIvIc8G/PPURfAjU4AwLOBW5V1fUiMg7n33aiqm4CHhGRs4CFInKcqu7AhAXrQzEhRVUfBobjjOB6AOfLeSHODYa/w9Px62mlpAMlONfeF+Fcqz9dVVfVO9+bOF/s8cB8nLXJ78O5NPZZAEO/GGeU1AU4AwMWAMfgvZ+nNrZ/AucDAzzxv4UzRDcK+N9BxHAvzhDp+cBXeIbhBpqqFuIk+EKcz/5RnNaItzv0f4PzuVyIM8PBv4HrgQ3Adk8CfgJ4RlWfrve6y3H+SFgoIgfc32JCky0BbIwxJiCshWKMMSYgLKEYY4wJCEsoxhhjAsISijHGmICwhGKMMSYgLKEYY4wJCEsoxhhjAsISijHGmID4f3XrllFqDyuxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(rr.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Ridge; $\\alpha = 0.01$',zorder=7) \n",
    "plt.plot(rr100.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Ridge; $\\alpha = 100$') \n",
    "plt.plot(lr.coef_,alpha=0.4,linestyle='none',marker='o',markersize=7,color='green',label='Linear Regression')\n",
    "plt.xlabel('Coefficient Index',fontsize=16)\n",
    "plt.ylabel('Coefficient Magnitude',fontsize=16)\n",
    "plt.legend(fontsize=13,loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. Lasso Regression\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "$$Lasso : \\lambda \\sum_{i=1}^{n} |\\theta_i| $$\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*P5Lq5mAi4WAch7oIeiS3WA.png\" width=400>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*JH9eAS2I9mwOpuFLg-gD6g.png\" width=300>\n",
    "\n",
    "Lasso √© outra varia√ß√£o de regulariza√ß√£o, em que a fun√ß√£o acima √© minimizada. √â claro que essa varia√ß√£o difere da regress√£o de Ridge apenas em penalizar os altos coeficientes. Ele usa | $\\theta_i$ | (m√≥dulo) em vez de quadrados de $\\theta_i$, como sua penalidade. Nas estat√≠sticas, isso √© conhecido como a norma L1.\n",
    "\n",
    "Vamos dar uma olhada nos m√©todos acima com uma perspectiva diferente: a regress√£o de Ridge pode ser pensada como resolvendo uma equa√ß√£o, onde a soma dos quadrados dos coeficientes √© menor ou igual a s. E o Lasso pode ser pensado como uma equa√ß√£o onde a soma do m√≥dulo de coeficientes √© menor ou igual a s. Aqui, s √© uma constante que existe para cada valor do fator de encolhimento Œª. Essas equa√ß√µes tamb√©m s√£o chamadas de fun√ß√µes de restri√ß√£o.\n",
    "\n",
    "Considere os seus dois par√¢metros em um determinado problema. Ent√£o, de acordo com a formula√ß√£o acima, a regress√£o de Ridge √© expressa por $\\theta_1^2 +  \\theta_2^2 ‚â§ c$. Isto implica que os coeficientes de regress√£o de Ridge t√™m a menor RSS (fun√ß√£o de perda) para todos os pontos que se encontram dentro da circunfer√™ncia dada por $\\theta_1^2 +  \\theta_2^2 ‚â§ c$.\n",
    "\n",
    "Da mesma forma, para Lasso, a equa√ß√£o se torna $ |\\theta_1| +  |\\theta_2| ‚â§ t $. Isto implica que os coeficientes de Lasso possuem o menor RSS (fun√ß√£o de perda) para todos os pontos que est√£o dentro do diamante dado por $ |\\theta_1| +  |\\theta_2| ‚â§ t $.\n",
    "\n",
    "<br>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*Jd03Hyt2bpEv1r7UijLlpg.png\" style=\"height:350px\">\n",
    "<br>\n",
    "\n",
    "A imagem acima mostra as fun√ß√µes de restri√ß√£o (√°reas verdes), para Lasso (esquerda) e regress√£o de Ridge (direita), juntamente com contornos para RSS (elipse vermelha). Pontos na elipse compartilham o valor do RSS. Para um valor muito grande de s, as regi√µes verdes conter√£o o centro da elipse, fazendo estimativas de coeficiente de ambas as t√©cnicas de regress√£o, iguais √†s estimativas de m√≠nimos quadrados. Mas, este n√£o √© o caso na imagem acima. Nesse caso, as estimativas do coeficiente de regress√£o de Lasso e Ridge s√£o fornecidas pelo primeiro ponto em que uma elipse entra em contato com a regi√£o de restri√ß√£o. Como a regress√£o de Ridge possui uma restri√ß√£o circular sem pontos agudos, essa interse√ß√£o geralmente n√£o ocorre em um eixo e, portanto, as estimativas do coeficiente de regress√£o de Ridge ser√£o exclusivamente diferentes de zero. No entanto, a restri√ß√£o de Lasso tem cantos em cada um dos eixos e, portanto, a elipse geralmente cruza a regi√£o de restri√ß√£o em um eixo. Quando isso ocorre, um dos coeficientes ser√° igual a zero. Em dimens√µes mais altas (onde os par√¢metros s√£o muito maiores que 2), muitas das estimativas de coeficiente podem ser iguais a zero simultaneamente.\n",
    "\n",
    "Isso esclarece a desvantagem √≥bvia da regress√£o de Ridge, que √© a interpretabilidade do modelo. Reduzir√° os coeficientes dos preditores menos importantes, muito pr√≥ximos de zero. Mas isso nunca os tornar√° exatamente zero. Em outras palavras, o modelo final incluir√° todos os preditores. No entanto, no caso do Lasso, a penalidade de L1 tem o efeito de for√ßar algumas das estimativas de coeficiente a serem exatamente iguais a zero quando o par√¢metro de ajuste Œª √© suficientemente grande. Portanto, o m√©todo do Lasso tamb√©m realiza sele√ß√£o de vari√°veis ‚Äã‚Äãe √© dito que produz modelos escassos.\n",
    "\n",
    "## 3. ElasticNet Regression (L1 + L2)\n",
    "\n",
    "A regress√£o ElasticNet combina o poder da regress√£o Ridge e Lasso em um algoritmo. O que isso significa √© que, com a ElasticNet, o algoritmo pode remover vari√°veis fracas como no Lasso ou reduzi-las a quase zero como no Ridge. Todos esses algoritmos s√£o exemplos de Regulariza√ß√£o.\n",
    "\n",
    "Para ler mais acesse o artigo [Elastic Net Regression in Python](https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "\n",
    "## Trade-off entre vi√©s e vari√¢ncia\n",
    "\n",
    "O modelo de regress√£o linear simples, no qual voc√™ pretende predizer n observa√ß√µes da vari√°vel de resposta, Y, com uma combina√ß√£o linear de m vari√°veis preditoras, X e um termo de erro normalmente distribu√≠do com varia√ß√£o œÉ2, √© definido por uma equa√ß√£o linear. Como n√£o conhecemos os par√¢metros verdadeiros, temos que estimar esses par√¢metros a partir da amostra. Na abordagem de m√≠nimos quadrados ordin√°rios (OLS), estimamos-os como Œ≤ estimados de tal maneira que a soma dos quadrados dos res√≠duos √© a menor poss√≠vel. \n",
    "\n",
    "\n",
    "\n",
    "Para ler mais acesse o artigo [Regularization: Ridge, Lasso and Elastic Net](https://www.datacamp.com/community/tutorials/tutorial-ridge-lasso-elastic-net)\n",
    "\n",
    "## O que a Regulariza√ß√£o faz exatamente?\n",
    "\n",
    "Um modelo padr√£o de m√≠nimos quadrados tende a apresentar alguma varia√ß√£o, ou seja, esse modelo n√£o generaliza bem para um conjunto de dados diferente dos dados de treinamento. **A regulariza√ß√£o reduz significativamente a vari√¢ncia do modelo, sem aumento substancial de seu vi√©s.** Portanto, o par√¢metro de ajuste Œª, usado nas t√©cnicas de regulariza√ß√£o descritas acima, controla o impacto na varia√ß√£o. √Ä medida que o valor de Œª aumenta, reduz o valor dos coeficientes e, assim, reduz a varia√ß√£o. At√© certo ponto, esse aumento em Œª √© ben√©fico, pois reduz apenas a varia√ß√£o (evitando, portanto, o ajuste excessivo), sem perder propriedades importantes nos dados. Mas, ap√≥s um certo valor, o modelo come√ßa a perder propriedades importantes, dando origem a um vi√©s no modelo e, portanto, a um ajuste insuficiente. Portanto, o valor de Œª deve ser cuidadosamente selecionado.\n",
    "\n",
    "√â tudo o que voc√™ precisa para come√ßar a regularizar. √â uma t√©cnica √∫til que pode ajudar a melhorar a precis√£o dos seus modelos de regress√£o. Uma biblioteca popular para implementar esses algoritmos √© o Scikit-Learn. Ele tem uma API maravilhosa que pode fazer seu modelo funcionar com apenas algumas linhas de c√≥digo em python.\n",
    "\n",
    "Artigo original [Regularization in Machine Learning](https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Um pouco de Pr√°tica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O desemprego √© uma grande preocupa√ß√£o socioecon√¥mica e pol√≠tica para qualquer pa√≠s e, portanto, gerenci√°-lo √© a principal tarefa de qualquer governo. Nesta pr√°tica, tentaremos construir algoritmos de regress√£o para prever o desemprego em uma economia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos definir o Passo a Passo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Carregar as bibliotecas, m√≥dulos, classes e fun√ß√µes\n",
    "- Carregar os dados\n",
    "- Definir os preditores e a vari√°vel resposta\n",
    "- Criar os conjuntos de treino e teste\n",
    "- Construir os modelos de regress√£o, prever e avaliar os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(574, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pce</th>\n",
       "      <th>pop</th>\n",
       "      <th>psavert</th>\n",
       "      <th>uempmed</th>\n",
       "      <th>unemploy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.500000</td>\n",
       "      <td>4820.092683</td>\n",
       "      <td>257159.652662</td>\n",
       "      <td>8.567247</td>\n",
       "      <td>8.608711</td>\n",
       "      <td>7771.310105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>165.843802</td>\n",
       "      <td>3556.803613</td>\n",
       "      <td>36682.398508</td>\n",
       "      <td>2.964179</td>\n",
       "      <td>4.106645</td>\n",
       "      <td>2641.959180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>506.700000</td>\n",
       "      <td>198712.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>144.250000</td>\n",
       "      <td>1578.300000</td>\n",
       "      <td>224896.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>287.500000</td>\n",
       "      <td>3936.850000</td>\n",
       "      <td>253060.000000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>430.750000</td>\n",
       "      <td>7626.325000</td>\n",
       "      <td>290290.750000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>8685.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>574.000000</td>\n",
       "      <td>12193.800000</td>\n",
       "      <td>320402.295000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>25.200000</td>\n",
       "      <td>15352.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           pce            pop     psavert     uempmed  \\\n",
       "count  574.000000    574.000000     574.000000  574.000000  574.000000   \n",
       "mean   287.500000   4820.092683  257159.652662    8.567247    8.608711   \n",
       "std    165.843802   3556.803613   36682.398508    2.964179    4.106645   \n",
       "min      1.000000    506.700000  198712.000000    2.200000    4.000000   \n",
       "25%    144.250000   1578.300000  224896.000000    6.400000    6.000000   \n",
       "50%    287.500000   3936.850000  253060.000000    8.400000    7.500000   \n",
       "75%    430.750000   7626.325000  290290.750000   11.100000    9.100000   \n",
       "max    574.000000  12193.800000  320402.295000   17.300000   25.200000   \n",
       "\n",
       "           unemploy  \n",
       "count    574.000000  \n",
       "mean    7771.310105  \n",
       "std     2641.959180  \n",
       "min     2685.000000  \n",
       "25%     6284.000000  \n",
       "50%     7494.000000  \n",
       "75%     8685.500000  \n",
       "max    15352.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('unemployment_data.csv')\n",
    "print(df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0' , axis=1,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pce</th>\n",
       "      <th>pop</th>\n",
       "      <th>psavert</th>\n",
       "      <th>uempmed</th>\n",
       "      <th>unemploy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>574.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.395290</td>\n",
       "      <td>0.802615</td>\n",
       "      <td>0.495217</td>\n",
       "      <td>0.341616</td>\n",
       "      <td>7771.310105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.291690</td>\n",
       "      <td>0.114489</td>\n",
       "      <td>0.171340</td>\n",
       "      <td>0.162962</td>\n",
       "      <td>2641.959180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.041554</td>\n",
       "      <td>0.620195</td>\n",
       "      <td>0.127168</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>2685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.129435</td>\n",
       "      <td>0.701918</td>\n",
       "      <td>0.369942</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>6284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.322857</td>\n",
       "      <td>0.789820</td>\n",
       "      <td>0.485549</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>7494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.625426</td>\n",
       "      <td>0.906020</td>\n",
       "      <td>0.641618</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>8685.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15352.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pce         pop     psavert     uempmed      unemploy\n",
       "count  574.000000  574.000000  574.000000  574.000000    574.000000\n",
       "mean     0.395290    0.802615    0.495217    0.341616   7771.310105\n",
       "std      0.291690    0.114489    0.171340    0.162962   2641.959180\n",
       "min      0.041554    0.620195    0.127168    0.158730   2685.000000\n",
       "25%      0.129435    0.701918    0.369942    0.238095   6284.000000\n",
       "50%      0.322857    0.789820    0.485549    0.297619   7494.000000\n",
       "75%      0.625426    0.906020    0.641618    0.361111   8685.500000\n",
       "max      1.000000    1.000000    1.000000    1.000000  15352.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = ['unemploy']\n",
    "predictors = list(set(list(df.columns))-set(target))\n",
    "df[predictors] = df[predictors]/df[predictors].max()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 4)\n",
      "(173, 4)\n"
     ]
    }
   ],
   "source": [
    "#Criar os conjuntos de treino e teste\n",
    "X = df[predictors].values\n",
    "y = df[target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=40)\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "986.4203778792611\n",
      "0.8643441807823631\n",
      "1044.7751718256557\n",
      "0.831615696708742\n"
     ]
    }
   ],
   "source": [
    "# Regress√£o linear\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Avalia√ß√£o Regress√£o Linear\n",
    "pred_train_lr= lr.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_lr)))\n",
    "print(r2_score(y_train, pred_train_lr))\n",
    "\n",
    "pred_test_lr= lr.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_lr))) \n",
    "print(r2_score(y_test, pred_test_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "990.8064876879897\n",
      "0.8631351138028003\n",
      "1040.3512413393082\n",
      "0.8330386695177573\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "rr = Ridge(alpha=0.01)\n",
    "rr.fit(X_train, y_train) \n",
    "pred_train_rr= rr.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_rr)))\n",
    "print(r2_score(y_train, pred_train_rr))\n",
    "\n",
    "pred_test_rr= rr.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_rr))) \n",
    "print(r2_score(y_test, pred_test_rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "986.4208828058871\n",
      "0.8643440419039413\n",
      "1044.6822216393111\n",
      "0.8316456565633901\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "model_lasso = Lasso(alpha=0.01)\n",
    "model_lasso.fit(X_train, y_train) \n",
    "pred_train_lasso= model_lasso.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_lasso)))\n",
    "print(r2_score(y_train, pred_train_lasso))\n",
    "\n",
    "pred_test_lasso= model_lasso.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_lasso))) \n",
    "print(r2_score(y_test, pred_test_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1353.5137565331572\n",
      "0.7445889364059675\n",
      "1380.6610280090797\n",
      "0.7059439969407901\n"
     ]
    }
   ],
   "source": [
    "#Elastic Net\n",
    "model_enet = ElasticNet(alpha = 0.01)\n",
    "model_enet.fit(X_train, y_train) \n",
    "pred_train_enet= model_enet.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_enet)))\n",
    "print(r2_score(y_train, pred_train_enet))\n",
    "\n",
    "pred_test_enet= model_enet.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_enet)))\n",
    "print(r2_score(y_test, pred_test_enet))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "nteract-on-jupyter@1.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
