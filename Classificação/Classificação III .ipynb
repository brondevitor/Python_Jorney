{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "\n",
    "Até agora estudamos classificação binária, na qual temos dois possíveis resultados.\n",
    "Denominamos uma das classes como sendo positiva (geralmente aquela cujo efeito queremos observar) e outra como sendo negativa, indicando ausência da característica que queremos observar.\n",
    "\n",
    "Embora esse tipo de classificação seja amplamente utilizado e represente a maioria dos problemas do dia a dia, podemos nos deparar com problemas multiclasse, aqueles em que existem mais de 2 rótulos possíveis para uma tupla. \n",
    "\n",
    "Vimos que aguns algoritmos lidam naturalmente com problemas multiclasse, ou seja, conseguem, de maneira nativa, lidar com esse tipo de problema, tais como KNN e Decision Trees. Outros, por sua vez, como Regressão Logística e SVM, não conseguem e, por isso, utilizam artifícios que iremos aprender a partir de agora.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação Multiclasse\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"https://dalab.github.io/dissolve-struct/images/multiclass.png\" align=\"center\" width=500>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs. Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira forma de tratar o problema multiclasse é utilizando a técnica One vs. Rest, que cria um modelo diferente, cada um especializado em uma das classes. Por tanto, teremos n modelos treinados, n sendo igual ao número de classes possíveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*RElrybCZ4WPsUfRwDl7fqA.png\" width=500>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No exemplo acima, temos 3 classes possíves: Green, Blue e Red. Dessa forma, Treinamos um primeiro modelo específico para a classe Green, em que Green é a classe positiva de interesse e todas as demais são consideradas como a classe negativa. E isso é feito para todas as demais classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No final do processo de treinamento, a classe cuja probabilide for a maior é escolhida. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs. One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"https://miro.medium.com/max/1056/1*4xjYPBsT9ZHOe3u0MIRB2A.jpeg\" width=400>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse método, para as N classes no target, precisamos criar N* (N-1)/2 classificadores \n",
    "binários.\n",
    "\n",
    "**Modelo 1**: Green vs. Blue<br>\n",
    "**Modelo  2**: Green vs. Red<br>\n",
    "**Modelo 3**: Blue vs. Red<br>\n",
    "Aqui, cada classificador prediz um único label. Para decidir qual a classe prevista, fazemos votação majoritária.\n",
    "Ou seja, escolhemos a classe que aparece no maior número de previsões binárias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como calculamos as métricas na classificação binária, podemos calculá-las para um classificador multiclasse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine um classificador que precise identificar gatos, cães e peixes. Dele extraímos a seguinte matriz de confusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*JqzG5_K4fWLa-_VFswQbxQ.png\" width=400>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asssim como calculamos precision, recall e f1-score para nossos modelos binários, também podemos calcular para casos multiclasse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*a5jVpe1Q5DbGBFR3rakyig.png\" width=400>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por exemplo, o precision para a classe gato é igual ao número de gatos classificados corretamente (TP) \n",
    "dividido pela quantidade de previsões de gato(TP+FP).\n",
    "Isso seria equivalente a Precision =  4/13=30.8%. \n",
    "Isso significa que apenas 30.8% das fotos classificadas como gatos são realmente gatos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por outro lado, o recall para a classe gato é quantidade de gatos identificados do total de gatos\n",
    "que seria 4/6=66.7%. De maneira análoga, podemos calcular precision e recall para as demais classes. For Fish the numbers are 66.7% and 20.0% respectively. For Hen the number for both precision and recall is 66.7%. Go ahead and verify these results. You can use the two images below to help you.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como na classificação binária, também teremos curvas ROC e PR, mas dessa vez para cada classe!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris = load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressão Logística One vs Rest\n",
    "reg_log = LogisticRegression(multi_class='ovr')\n",
    "reg_log.fit(df_iris.data, df_iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reg_log = reg_log.predict(df_iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.96      0.90      0.93        50\n",
      "           2       0.91      0.96      0.93        50\n",
      "\n",
      "    accuracy                           0.95       150\n",
      "   macro avg       0.95      0.95      0.95       150\n",
      "weighted avg       0.95      0.95      0.95       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_iris.target, y_pred_reg_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm_ovo = SVC(decision_function_shape='ovo')\n",
    "svm_ovr = SVC(decision_function_shape='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_ovo.fit(df_iris.data, df_iris.target)\n",
    "svm_ovr.fit(df_iris.data, df_iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_ovo = svm_ovo.predict(df_iris.data)\n",
    "y_pred_svm_ovr = svm_ovr.predict(df_iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.96      0.96      0.96        50\n",
      "           2       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_iris.target, y_pred_svm_ovo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.96      0.96      0.96        50\n",
      "           2       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_iris.target, y_pred_svm_ovr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que seriam Macro Avg e Weighted Avg??."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macro Avg e Weighted Avg são medidas resumo do precision, recall e f1-score. \n",
    "- Macro Avg: Média aritmética das métricas\n",
    "- Weighted Avg: Média ponderada das métricas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem ainda as métricas micro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src='https://phdstatsphys.files.wordpress.com/2018/10/Screenshot-from-2019-01-01-20-41-40.png'>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas métricas micro, aplicamos as fórmulas que já conhecemos, mas somamos todos os TP, todos os TN, todos os FN e todos os FP para calculá-las."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que temos pelo menos 9 métricas-resumo:\n",
    "- Macro Precision\n",
    "- Macro Recall\n",
    "- Macro F1\n",
    "- Micro Precision\n",
    "- Micro Recall\n",
    "- Micro F1\n",
    "- Weighted Precision\n",
    "- Weighted Recall\n",
    "- Weighted F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando estamos trabalhando com dados bem desbalanceados, as métricas Macro são melhores, pois dão um peso igual para todas as clases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
